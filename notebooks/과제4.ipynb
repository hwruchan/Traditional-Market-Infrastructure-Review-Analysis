{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ì „êµ­ ì „í†µì‹œì¥ ì‹œì„¤í˜„í™© + ì‹œì¥ë³„ ë¦¬ë·° í¬ë¡¤ë§ ë¶„ì„\n",
    "\n",
    "**í•™ë²ˆ:** 202210827  \n",
    "**ê³¼ì œ:** [ê³¼ì œì•ˆ 4] ì „êµ­ ì „í†µì‹œì¥ ì‹œì„¤í˜„í™© + ì‹œì¥ë³„ ë¦¬ë·° í¬ë¡¤ë§ ë¶„ì„  \n",
    "**ì œì¶œì¼:** 2024ë…„ 12ì›”\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ëª©ì°¨\n",
    "1. [ê³¼ì œ ëª©í‘œ](#1-ê³¼ì œ-ëª©í‘œ)\n",
    "2. [ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ê³¼ì •](#2-ë°ì´í„°-ìˆ˜ì§‘-ë°-ì „ì²˜ë¦¬-ê³¼ì •)\n",
    "3. [ë¶„ì„ ë°©ë²•](#3-ë¶„ì„-ë°©ë²•)\n",
    "4. [ë¶„ì„ ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸](#4-ë¶„ì„-ê²°ê³¼-ë°-ì¸ì‚¬ì´íŠ¸)\n",
    "5. [ì •ì±… ì œì•ˆ](#5-ì •ì±…-ì œì•ˆ)\n",
    "6. [ê²°ë¡ ](#6-ê²°ë¡ )\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. ê³¼ì œ ëª©í‘œ\n",
    "\n",
    "### 1.1 ì—°êµ¬ ëª©ì \n",
    "- **ì£¼ìš” ëª©í‘œ**: ì „êµ­ ì „í†µì‹œì¥ì˜ ì‹œì„¤í˜„í™©ê³¼ ì˜¨ë¼ì¸ ë¦¬ë·° ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ì‹œì¥ë³„ ë§Œì¡±ë„ì™€ ì‹œì„¤ ê°œì„  í•„ìš” ìš”ì¸ì„ ë¶„ì„\n",
    "- **ì„¸ë¶€ ëª©í‘œ**:\n",
    "  1. ì „í†µì‹œì¥ ì‹œì„¤í˜„í™© ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„\n",
    "  2. ì˜¨ë¼ì¸ ë¦¬ë·° ë°ì´í„° í¬ë¡¤ë§ì„ í†µí•œ ê³ ê° ë§Œì¡±ë„ íŒŒì•…\n",
    "  3. ì‹œì„¤í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "  4. ì „í†µì‹œì¥ í™œì„±í™”ë¥¼ ìœ„í•œ ì •ì±… ì œì•ˆ ë„ì¶œ\n",
    "\n",
    "### 1.2 ê¸°ëŒ€ íš¨ê³¼\n",
    "- ë°ì´í„° ê¸°ë°˜ì˜ ì „í†µì‹œì¥ í˜„í™© íŒŒì•…\n",
    "- ê³ ê° ë§Œì¡±ë„ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ë°©í–¥ ì œì‹œ\n",
    "- ì „í†µì‹œì¥ ì •ì±… ìˆ˜ë¦½ ì‹œ í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"âŒ {package} ì„¤ì¹˜ ì‹¤íŒ¨\")\n",
    "\n",
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ ì„¤ì¹˜\n",
    "required_packages = ['pandas', 'requests', 'beautifulsoup4', 'matplotlib', 'seaborn', 'wordcloud', 'numpy']\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"âœ… {package} ì´ë¯¸ ì„¤ì¹˜ë¨\")\n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...\")\n",
    "        install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# seabornê³¼ wordcloudëŠ” ì„ íƒì  ì„í¬íŠ¸ (ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ëŒ€ì²´ ë°©ë²• ì‚¬ìš©)\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    print(\"âœ… seaborn ì„í¬íŠ¸ ì„±ê³µ\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ seabornì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. matplotlibë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    sns = None\n",
    "\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    print(\"âœ… wordcloud ì„í¬íŠ¸ ì„±ê³µ\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ wordcloudë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ì‹œê°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    WordCloud = None\n",
    "\n",
    "print(\"ğŸ“š ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ê³¼ì •\n",
    "\n",
    "### 2.1 ë°ì´í„° ì†ŒìŠ¤\n",
    "1. **ì „êµ­ ì „í†µì‹œì¥ í˜„í™© ë°ì´í„°**: ê³µê³µë°ì´í„°í¬í„¸(data.go.kr)\n",
    "2. **ì˜¨ë¼ì¸ ë¦¬ë·° ë°ì´í„°**: ë„¤ì´ë²„ ì§€ë„/ì¹´ì¹´ì˜¤ë§µ í¬ë¡¤ë§\n",
    "\n",
    "### 2.2 ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•\n",
    "- ê³µê³µë°ì´í„°ëŠ” CSV í˜•íƒœë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "- ë¦¬ë·° ë°ì´í„°ëŠ” ì›¹ í¬ë¡¤ë§ì„ í†µí•´ ìˆ˜ì§‘ (requests + BeautifulSoup)\n",
    "- í¬ë¡¤ë§ ì‹œ ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°ì‹œê°„ ì„¤ì •\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 ì‹¤ì œ ì „í†µì‹œì¥ ë°ì´í„° ë¡œë“œ\n",
    "# ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì‹¤ì œ ì „í†µì‹œì¥ ë§¤ì¹­ ë°ì´í„° ë¡œë“œ\n",
    "try:\n",
    "    market_df = pd.read_csv('ì „í†µì‹œì¥_ë§¤ì¹­ë°ì´í„°.csv', encoding='utf-8')\n",
    "    print(\"âœ… ì‹¤ì œ ì „í†µì‹œì¥ ë°ì´í„° ë¡œë“œ ì„±ê³µ!\")\n",
    "except:\n",
    "    try:\n",
    "        market_df = pd.read_csv('ì „í†µì‹œì¥_ë§¤ì¹­ë°ì´í„°.csv', encoding='cp949')\n",
    "        print(\"âœ… ì‹¤ì œ ì „í†µì‹œì¥ ë°ì´í„° ë¡œë“œ ì„±ê³µ! (cp949 ì¸ì½”ë”©)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        # ë°±ì—… ë°ì´í„° ìƒì„±\n",
    "        market_df = pd.DataFrame()\n",
    "\n",
    "print(f\"ğŸ“Š ì´ {len(market_df)}ê°œ ì „í†µì‹œì¥ ë°ì´í„°\")\n",
    "print(f\"ğŸ“‹ ì»¬ëŸ¼ ìˆ˜: {len(market_df.columns)}ê°œ\")\n",
    "print(\"\\nğŸ” ë°ì´í„° ê¸°ë³¸ ì •ë³´:\")\n",
    "print(market_df.info())\n",
    "\n",
    "print(\"\\nğŸ“‹ ì£¼ìš” ì»¬ëŸ¼ë“¤:\")\n",
    "print(market_df.columns.tolist()[:10])  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ì œ\n",
    "# ì‹¤ì œ ë°ì´í„°ì˜ ì»¬ëŸ¼ëª…ì„ ì •ë¦¬í•˜ê³  ë¶„ì„ì— í•„ìš”í•œ í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "def preprocess_market_data(df):\n",
    "    \"\"\"ì „í†µì‹œì¥ ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"âŒ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return df\n",
    "    \n",
    "    # ì£¼ìš” ì»¬ëŸ¼ ì¶”ì¶œ ë° ì´ë¦„ ë³€ê²½\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # ì»¬ëŸ¼ëª… ë§¤í•‘ (ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ)\n",
    "    column_mapping = {\n",
    "        'ì‹œì¥ëª…_ì •ì œ': 'ì‹œì¥ëª…',\n",
    "        'ì‹œë„_íŒŒì¼1': 'ì‹œë„',\n",
    "        'ì‹œêµ°êµ¬_íŒŒì¼1': 'ì‹œêµ°êµ¬', \n",
    "        'ì í¬ìˆ˜_íŒŒì¼2': 'ì í¬ìˆ˜',\n",
    "        'ì•„ì¼€ì´ë“œ ë³´ìœ  ì—¬ë¶€_íŒŒì¼1': 'ì•„ì¼€ì´ë“œ',\n",
    "        'ì‹œì¥ì „ìš© ê³ ê°ì£¼ì°¨ì¥_ë³´ìœ ì—¬ë¶€_íŒŒì¼1': 'ì£¼ì°¨ì¥',\n",
    "        'ê³µì¤‘í™”ì¥ì‹¤ë³´ìœ ì—¬ë¶€_íŒŒì¼2': 'í™”ì¥ì‹¤',\n",
    "        'ê°œì„¤ì—°ë„_íŒŒì¼2': 'ê°œì„¤ì—°ë„',\n",
    "        'ì·¨ê¸‰í’ˆëª©_íŒŒì¼2': 'ì·¨ê¸‰í’ˆëª©',\n",
    "        'ì‹œì¥ìœ í˜•_íŒŒì¼2': 'ì‹œì¥ìœ í˜•'\n",
    "    }\n",
    "    \n",
    "    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë§¤í•‘\n",
    "    existing_columns = {}\n",
    "    for old_col, new_col in column_mapping.items():\n",
    "        if old_col in processed_df.columns:\n",
    "            existing_columns[old_col] = new_col\n",
    "    \n",
    "    processed_df = processed_df.rename(columns=existing_columns)\n",
    "    \n",
    "    # ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ì •ì œ\n",
    "    if 'ì í¬ìˆ˜' in processed_df.columns:\n",
    "        processed_df['ì í¬ìˆ˜'] = pd.to_numeric(processed_df['ì í¬ìˆ˜'], errors='coerce')\n",
    "    \n",
    "    if 'ê°œì„¤ì—°ë„' in processed_df.columns:\n",
    "        processed_df['ê°œì„¤ì—°ë„'] = pd.to_numeric(processed_df['ê°œì„¤ì—°ë„'], errors='coerce')\n",
    "        processed_df['ìš´ì˜ë…„ìˆ˜'] = 2024 - processed_df['ê°œì„¤ì—°ë„']\n",
    "    \n",
    "    # Y/N ê°’ì„ í•œê¸€ë¡œ ë³€í™˜\n",
    "    yn_columns = ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']\n",
    "    for col in yn_columns:\n",
    "        if col in processed_df.columns:\n",
    "            processed_df[col] = processed_df[col].map({'Y': 'ìˆìŒ', 'N': 'ì—†ìŒ'}).fillna('ì •ë³´ì—†ìŒ')\n",
    "    \n",
    "    print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    return processed_df\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰\n",
    "market_df_processed = preprocess_market_data(market_df)\n",
    "\n",
    "print(\"\\nğŸ“Š ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "if not market_df_processed.empty:\n",
    "    print(market_df_processed[['ì‹œì¥ëª…', 'ì‹œë„', 'ì í¬ìˆ˜', 'ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥']].head())\n",
    "else:\n",
    "    print(\"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "# numpyëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±ì—ë§Œ í•„ìš”í•˜ë¯€ë¡œ ì œê±°í•©ë‹ˆë‹¤.\n",
    "\n",
    "# 2.5 ë¦¬ë·° ë°ì´í„° í¬ë¡¤ë§ í•¨ìˆ˜ ì •ì˜\n",
    "# (ë„¤ì´ë²„ ì§€ë„ í¬ë¡¤ë§ì€ ë™ì  ì½˜í…ì¸ ë¡œ ì¸í•´ requests+BeautifulSoupë§Œìœ¼ë¡œëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "#  ì‹¤ì œ ë™ì‘ì„ ìœ„í•´ì„œëŠ” Seleniumê³¼ ê°™ì€ headless browser ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "#  ì—¬ê¸°ì„œëŠ” requests+BeautifulSoupë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ì ì¸ ì‹œë„ë¥¼ ë³´ì—¬ì£¼ë©°, ë°ì´í„° ì¶”ì¶œì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n",
    "\n",
    "def get_review_data(market_name):\n",
    "    \"\"\"\n",
    "    ë„¤ì´ë²„ ì§€ë„ì—ì„œ ì‹œì¥ ë¦¬ë·° ë°ì´í„°ë¥¼ í¬ë¡¤ë§ ì‹œë„.\n",
    "    ë™ì  ì½˜í…ì¸ ë¡œ ì¸í•´ requests + BeautifulSoupë§Œìœ¼ë¡œëŠ” ì •í™•í•œ í‰ì /ë¦¬ë·°ìˆ˜ ì¶”ì¶œì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì‹¤ì œ í¬ë¡¤ë§ ì‹œì—ëŠ” Seleniumê³¼ ê°™ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ JavaScriptê°€ ë Œë”ë§ëœ í›„ì˜ HTMLì„ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    base_url = \"https://map.naver.com/v5/search/\"\n",
    "    # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì‹œì¥ëª… ë’¤ì— 'ì „í†µì‹œì¥'ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "    search_query = f\"{market_name} ì „í†µì‹œì¥\" \n",
    "    url = f\"{base_url}{search_query}\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    rating = 0.0 # í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’\n",
    "    review_count = 0 # í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’\n",
    "    \n",
    "    try:\n",
    "        # HTTP ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤. íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€.\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status() # 4xx, 5xx ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # --- ì¤‘ìš”: ë„¤ì´ë²„ ì§€ë„ì™€ ê°™ì€ ë™ì  ì›¹í˜ì´ì§€ í¬ë¡¤ë§ì˜ í•œê³„ ---\n",
    "        # requests+BeautifulSoupëŠ” ì›¹í˜ì´ì§€ì˜ ì •ì  HTMLë§Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        # ë„¤ì´ë²„ ì§€ë„ì˜ í‰ì , ë¦¬ë·° ìˆ˜ ë“±ì€ JavaScriptì— ì˜í•´ ë™ì ìœ¼ë¡œ ë¡œë“œë˜ë¯€ë¡œ,\n",
    "        # ì´ ë°©ë²•ìœ¼ë¡œëŠ” í•´ë‹¹ ë°ì´í„°ë¥¼ ì§ì ‘ ì¶”ì¶œí•˜ê¸° ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "        # ì•„ë˜ì˜ CSS ì„ íƒìëŠ” ì˜ˆì‹œì´ë©°, ì‹¤ì œë¡œëŠ” ì‘ë™í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n",
    "        # ì‹¤ì œ ë°ì´í„°ë¥¼ ì–»ìœ¼ë ¤ë©´ Seleniumê³¼ ê°™ì€ headless browser ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "        # ì˜ˆì‹œ: í‰ì ê³¼ ë¦¬ë·°ìˆ˜ë¥¼ í¬í•¨í•  ìˆ˜ ìˆëŠ” ìš”ì†Œ íƒìƒ‰ (ì‹¤ì œë¡œëŠ” ì°¾ê¸° ì–´ë ¤ì›€)\n",
    "        # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ë„¤ì´ë²„ ì§€ë„ í˜ì´ì§€ì˜ HTML ì†ŒìŠ¤ë¥¼ ë³´ê³  ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        # í˜„ì¬ requests+BeautifulSoupë¡œëŠ” ë™ì  ë¡œë”©ë˜ëŠ” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ì–´ë µê¸° ë•Œë¬¸ì—,\n",
    "        # ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ê¸°ë³¸ê°’(0.0, 0)ì´ ë°˜í™˜ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "        \n",
    "        # í‰ì  ì¶”ì¶œ ì‹œë„ (ì˜ˆì‹œ ì„ íƒì, ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)\n",
    "        rating_element = soup.find('span', class_='_score') \n",
    "        if rating_element:\n",
    "            try:\n",
    "                rating = float(rating_element.text.strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # ë¦¬ë·°ìˆ˜ ì¶”ì¶œ ì‹œë„ (ì˜ˆì‹œ ì„ íƒì, ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)\n",
    "        review_count_element = soup.find('span', class_='_reviewCount') \n",
    "        if review_count_element:\n",
    "            try:\n",
    "                review_count_text = review_count_element.text.strip().replace(',', '')\n",
    "                review_count = int(review_count_text.strip('()'))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        if rating == 0.0 and review_count == 0:\n",
    "            print(f\"âš ï¸ '{market_name}'ì— ëŒ€í•œ ë¦¬ë·° ë°ì´í„°ë¥¼ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤. (ë™ì  ì½˜í…ì¸  ë¬¸ì œ ë˜ëŠ” ë°ì´í„° ì—†ìŒ)\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜ ë°œìƒ ({market_name}): {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜ ({market_name}): {e}\")\n",
    "        \n",
    "    return rating, review_count\n",
    "\n",
    "def get_market_reviews(market_df):\n",
    "    \"\"\"ì „í†µì‹œì¥ë³„ ë¦¬ë·° ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\"\"\"\n",
    "    \n",
    "    if market_df.empty:\n",
    "        print(\"âŒ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì–´ ë¦¬ë·° ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return market_df\n",
    "    \n",
    "    print(\"ğŸ•·ï¸ ë¦¬ë·° ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘...\")\n",
    "    \n",
    "    ratings = []\n",
    "    review_counts = []\n",
    "    \n",
    "    # ì‹¤ì œ í¬ë¡¤ë§ ì‹œì—ëŠ” ì„œë²„ì— ê³¼ë„í•œ ë¶€í•˜ë¥¼ ì£¼ì§€ ì•Šê¸° ìœ„í•´ ì¶©ë¶„í•œ ì§€ì—° ì‹œê°„ì„ ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    CRAWL_DELAY = 1.0 # ì‹¤ì œ í¬ë¡¤ë§ì´ë¯€ë¡œ ì§€ì—° ì‹œê°„ì„ ëŠ˜ë¦¼ (ì´ˆ ë‹¨ìœ„)\n",
    "    \n",
    "    for idx, row in market_df.iterrows():\n",
    "        market_name = row.get('ì‹œì¥ëª…', f'ì‹œì¥_{idx}')\n",
    "        \n",
    "        # ë¦¬ë·° ë°ì´í„° í¬ë¡¤ë§ ì‹œë„\n",
    "        rating, review_count = get_review_data(market_name)\n",
    "        \n",
    "        ratings.append(rating)\n",
    "        review_counts.append(review_count)\n",
    "        \n",
    "        # ì§„í–‰ ìƒí™© í‘œì‹œ ë° ì§€ì—° ì‹œê°„\n",
    "        time.sleep(CRAWL_DELAY)\n",
    "        \n",
    "        # 10ê°œ ì‹œì¥ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ì‹œì¥ì¼ ë•Œ ì§„í–‰ë¥  ì¶œë ¥\n",
    "        if (idx + 1) % 10 == 0 or (idx + 1) == len(market_df):\n",
    "            print(f\"ì§„í–‰ë¥ : {idx+1}/{len(market_df)} ({(idx+1)/len(market_df)*100:.1f}%) - í˜„ì¬ ì‹œì¥: {market_name}\")\n",
    "    \n",
    "    # í¬ë¡¤ë§ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "    market_df_with_reviews = market_df.copy()\n",
    "    market_df_with_reviews['í‰ì '] = ratings\n",
    "    market_df_with_reviews['ë¦¬ë·°ìˆ˜'] = review_counts\n",
    "    \n",
    "    print(\"âœ… ë¦¬ë·° ë°ì´í„° í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "    return market_df_with_reviews\n",
    "\n",
    "# ë¦¬ë·° ë°ì´í„° ìƒì„± (í¬ë¡¤ë§ í•¨ìˆ˜ í˜¸ì¶œ)\n",
    "market_df_final = get_market_reviews(market_df_processed)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. ë¶„ì„ ë°©ë²•\n",
    "\n",
    "### 3.1 ë¶„ì„ ì ‘ê·¼ë²•\n",
    "1. **ê¸°ìˆ í†µê³„ ë¶„ì„**: ì „í†µì‹œì¥ í˜„í™© íŒŒì•…\n",
    "2. **ì‹œê°í™” ë¶„ì„**: ì§€ì—­ë³„, ì‹œì„¤ë³„ ë¶„í¬ í˜„í™©\n",
    "3. **ìƒê´€ê´€ê³„ ë¶„ì„**: ì‹œì„¤í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ ê°„ì˜ ê´€ê³„\n",
    "4. **í‚¤ì›Œë“œ ë¶„ì„**: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "\n",
    "### 3.2 ë¶„ì„ ë„êµ¬\n",
    "- **Python**: pandas, matplotlib, seaborn\n",
    "- **í†µê³„ ë¶„ì„**: ìƒê´€ê³„ìˆ˜, íšŒê·€ë¶„ì„\n",
    "- **ì‹œê°í™”**: íˆìŠ¤í† ê·¸ë¨, ì‚°ì ë„, íˆíŠ¸ë§µ, ì›Œë“œí´ë¼ìš°ë“œ\n",
    "\n",
    "### 3.3 ë¶„ì„ ì§€í‘œ\n",
    "- **ì‹œì„¤ í˜„í™©**: ì•„ì¼€ì´ë“œ, ì£¼ì°¨ì¥, í™”ì¥ì‹¤ ë³´ìœ ìœ¨\n",
    "- **ê³ ê° ë§Œì¡±ë„**: í‰ì , ë¦¬ë·° ìˆ˜\n",
    "- **ìš´ì˜ í˜„í™©**: ì í¬ ìˆ˜, ìš´ì˜ ë…„ìˆ˜, ì‹œì¥ ìœ í˜•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 ê¸°ë³¸ í†µê³„ ë¶„ì„\n",
    "# ì „í†µì‹œì¥ í˜„í™©ì— ëŒ€í•œ ê¸°ìˆ í†µê³„ ë¶„ì„\n",
    "\n",
    "def analyze_basic_statistics(df):\n",
    "    \"\"\"ê¸°ë³¸ í†µê³„ ë¶„ì„ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ“Š ì „êµ­ ì „í†µì‹œì¥ í˜„í™© ê¸°ë³¸ í†µê³„\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ì „ì²´ ì‹œì¥ ìˆ˜\n",
    "    total_markets = len(df)\n",
    "    print(f\"ğŸª ì´ ì „í†µì‹œì¥ ìˆ˜: {total_markets:,}ê°œ\")\n",
    "    \n",
    "    # ì§€ì—­ë³„ ë¶„í¬\n",
    "    if 'ì‹œë„' in df.columns:\n",
    "        region_dist = df['ì‹œë„'].value_counts()\n",
    "        print(f\"\\nğŸ“ ì§€ì—­ë³„ ì‹œì¥ ë¶„í¬ (ìƒìœ„ 5ê°œ ì§€ì—­):\")\n",
    "        for region, count in region_dist.head().items():\n",
    "            print(f\"   {region}: {count}ê°œ ({count/total_markets*100:.1f}%)\")\n",
    "    \n",
    "    # ì í¬ìˆ˜ í†µê³„\n",
    "    if 'ì í¬ìˆ˜' in df.columns:\n",
    "        store_stats = df['ì í¬ìˆ˜'].describe()\n",
    "        print(f\"\\nğŸ¬ ì í¬ìˆ˜ í†µê³„:\")\n",
    "        print(f\"   í‰ê· : {store_stats['mean']:.1f}ê°œ\")\n",
    "        print(f\"   ì¤‘ì•™ê°’: {store_stats['50%']:.1f}ê°œ\")\n",
    "        print(f\"   ìµœëŒ€: {store_stats['max']:.0f}ê°œ\")\n",
    "        print(f\"   ìµœì†Œ: {store_stats['min']:.0f}ê°œ\")\n",
    "    \n",
    "    # ì‹œì„¤ ë³´ìœ ìœ¨\n",
    "    facility_columns = ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']\n",
    "    print(f\"\\nğŸ—ï¸ ì‹œì„¤ ë³´ìœ ìœ¨:\")\n",
    "    for col in facility_columns:\n",
    "        if col in df.columns:\n",
    "            has_facility = (df[col] == 'ìˆìŒ').sum()\n",
    "            rate = has_facility / total_markets * 100\n",
    "            print(f\"   {col}: {has_facility}ê°œ ({rate:.1f}%)\")\n",
    "    \n",
    "    # í‰ì  ë° ë¦¬ë·° í†µê³„\n",
    "    if 'í‰ì ' in df.columns:\n",
    "        rating_stats = df['í‰ì '].describe()\n",
    "        print(f\"\\nâ­ í‰ì  í†µê³„:\")\n",
    "        print(f\"   í‰ê·  í‰ì : {rating_stats['mean']:.2f}ì \")\n",
    "        print(f\"   ìµœê³  í‰ì : {rating_stats['max']:.1f}ì \")\n",
    "        print(f\"   ìµœì € í‰ì : {rating_stats['min']:.1f}ì \")\n",
    "    \n",
    "    if 'ë¦¬ë·°ìˆ˜' in df.columns:\n",
    "        review_stats = df['ë¦¬ë·°ìˆ˜'].describe()\n",
    "        print(f\"\\nğŸ’¬ ë¦¬ë·°ìˆ˜ í†µê³„:\")\n",
    "        print(f\"   í‰ê·  ë¦¬ë·°ìˆ˜: {review_stats['mean']:.1f}ê°œ\")\n",
    "        print(f\"   ìµœëŒ€ ë¦¬ë·°ìˆ˜: {review_stats['max']:.0f}ê°œ\")\n",
    "    \n",
    "    # ìš´ì˜ë…„ìˆ˜ í†µê³„\n",
    "    if 'ìš´ì˜ë…„ìˆ˜' in df.columns:\n",
    "        age_stats = df['ìš´ì˜ë…„ìˆ˜'].describe()\n",
    "        print(f\"\\nğŸ“… ìš´ì˜ë…„ìˆ˜ í†µê³„:\")\n",
    "        print(f\"   í‰ê·  ìš´ì˜ë…„ìˆ˜: {age_stats['mean']:.1f}ë…„\")\n",
    "        print(f\"   ìµœì¥ ìš´ì˜: {age_stats['max']:.0f}ë…„\")\n",
    "        print(f\"   ìµœë‹¨ ìš´ì˜: {age_stats['min']:.0f}ë…„\")\n",
    "\n",
    "# ê¸°ë³¸ í†µê³„ ë¶„ì„ ì‹¤í–‰\n",
    "analyze_basic_statistics(market_df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 ì‹œê°í™” ë¶„ì„\n",
    "# ë‹¤ì–‘í•œ ì°¨íŠ¸ë¥¼ í†µí•œ ì „í†µì‹œì¥ í˜„í™© ì‹œê°í™”\n",
    "\n",
    "def create_visualizations(df):\n",
    "    \"\"\"ì „í†µì‹œì¥ ë°ì´í„° ì‹œê°í™” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. ì§€ì—­ë³„ ì‹œì¥ ë¶„í¬\n",
    "    if 'ì‹œë„' in df.columns:\n",
    "        plt.subplot(3, 3, 1)\n",
    "        region_counts = df['ì‹œë„'].value_counts().head(10)\n",
    "        plt.bar(range(len(region_counts)), region_counts.values, color='skyblue')\n",
    "        plt.title('ì§€ì—­ë³„ ì „í†µì‹œì¥ ë¶„í¬ (ìƒìœ„ 10ê°œ)', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('ì§€ì—­')\n",
    "        plt.ylabel('ì‹œì¥ ìˆ˜')\n",
    "        plt.xticks(range(len(region_counts)), region_counts.index, rotation=45)\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for i, v in enumerate(region_counts.values):\n",
    "            plt.text(i, v + 5, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # 2. ì í¬ìˆ˜ ë¶„í¬\n",
    "    if 'ì í¬ìˆ˜' in df.columns:\n",
    "        plt.subplot(3, 3, 2)\n",
    "        valid_stores = df['ì í¬ìˆ˜'].dropna()\n",
    "        plt.hist(valid_stores, bins=30, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "        plt.title('ì í¬ìˆ˜ ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('ì í¬ìˆ˜')\n",
    "        plt.ylabel('ì‹œì¥ ìˆ˜')\n",
    "        plt.axvline(valid_stores.mean(), color='red', linestyle='--', \n",
    "                   label=f'í‰ê· : {valid_stores.mean():.1f}ê°œ')\n",
    "        plt.legend()\n",
    "    \n",
    "    # 3. ì‹œì„¤ ë³´ìœ ìœ¨\n",
    "    plt.subplot(3, 3, 3)\n",
    "    facility_data = []\n",
    "    facility_labels = []\n",
    "    \n",
    "    for facility in ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']:\n",
    "        if facility in df.columns:\n",
    "            has_facility = (df[facility] == 'ìˆìŒ').sum()\n",
    "            rate = has_facility / len(df) * 100\n",
    "            facility_data.append(rate)\n",
    "            facility_labels.append(facility)\n",
    "    \n",
    "    if facility_data:\n",
    "        colors = ['#ff9999', '#66b3ff', '#99ff99']\n",
    "        plt.bar(facility_labels, facility_data, color=colors[:len(facility_data)])\n",
    "        plt.title('ì‹œì„¤ ë³´ìœ ìœ¨', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('ë³´ìœ ìœ¨ (%)')\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for i, v in enumerate(facility_data):\n",
    "            plt.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. í‰ì  ë¶„í¬\n",
    "    if 'í‰ì ' in df.columns:\n",
    "        plt.subplot(3, 3, 4)\n",
    "        valid_ratings = df['í‰ì '].dropna()\n",
    "        plt.hist(valid_ratings, bins=20, color='gold', alpha=0.7, edgecolor='black')\n",
    "        plt.title('í‰ì  ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('í‰ì ')\n",
    "        plt.ylabel('ì‹œì¥ ìˆ˜')\n",
    "        plt.axvline(valid_ratings.mean(), color='red', linestyle='--',\n",
    "                   label=f'í‰ê· : {valid_ratings.mean():.2f}ì ')\n",
    "        plt.legend()\n",
    "    \n",
    "    # 5. ë¦¬ë·°ìˆ˜ ë¶„í¬\n",
    "    if 'ë¦¬ë·°ìˆ˜' in df.columns:\n",
    "        plt.subplot(3, 3, 5)\n",
    "        valid_reviews = df['ë¦¬ë·°ìˆ˜'].dropna()\n",
    "        plt.hist(valid_reviews, bins=30, color='orange', alpha=0.7, edgecolor='black')\n",
    "        plt.title('ë¦¬ë·°ìˆ˜ ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('ë¦¬ë·°ìˆ˜')\n",
    "        plt.ylabel('ì‹œì¥ ìˆ˜')\n",
    "        plt.axvline(valid_reviews.mean(), color='red', linestyle='--',\n",
    "                   label=f'í‰ê· : {valid_reviews.mean():.1f}ê°œ')\n",
    "        plt.legend()\n",
    "    \n",
    "    # 6. ì í¬ìˆ˜ vs í‰ì  ì‚°ì ë„\n",
    "    if 'ì í¬ìˆ˜' in df.columns and 'í‰ì ' in df.columns:\n",
    "        plt.subplot(3, 3, 6)\n",
    "        valid_data = df[['ì í¬ìˆ˜', 'í‰ì ']].dropna()\n",
    "        plt.scatter(valid_data['ì í¬ìˆ˜'], valid_data['í‰ì '], alpha=0.6, color='purple')\n",
    "        plt.title('ì í¬ìˆ˜ vs í‰ì ', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('ì í¬ìˆ˜')\n",
    "        plt.ylabel('í‰ì ')\n",
    "        \n",
    "        # ì¶”ì„¸ì„  ì¶”ê°€\n",
    "        if len(valid_data) > 1:\n",
    "            z = np.polyfit(valid_data['ì í¬ìˆ˜'], valid_data['í‰ì '], 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(valid_data['ì í¬ìˆ˜'], p(valid_data['ì í¬ìˆ˜']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # 7. ìš´ì˜ë…„ìˆ˜ ë¶„í¬\n",
    "    if 'ìš´ì˜ë…„ìˆ˜' in df.columns:\n",
    "        plt.subplot(3, 3, 7)\n",
    "        valid_age = df['ìš´ì˜ë…„ìˆ˜'].dropna()\n",
    "        valid_age = valid_age[valid_age >= 0]  # ìŒìˆ˜ ì œê±°\n",
    "        plt.hist(valid_age, bins=25, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "        plt.title('ìš´ì˜ë…„ìˆ˜ ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('ìš´ì˜ë…„ìˆ˜')\n",
    "        plt.ylabel('ì‹œì¥ ìˆ˜')\n",
    "        plt.axvline(valid_age.mean(), color='red', linestyle='--',\n",
    "                   label=f'í‰ê· : {valid_age.mean():.1f}ë…„')\n",
    "        plt.legend()\n",
    "    \n",
    "    # 8. ì‹œì¥ìœ í˜•ë³„ ë¶„í¬\n",
    "    if 'ì‹œì¥ìœ í˜•' in df.columns:\n",
    "        plt.subplot(3, 3, 8)\n",
    "        market_types = df['ì‹œì¥ìœ í˜•'].value_counts()\n",
    "        plt.pie(market_types.values, labels=market_types.index, autopct='%1.1f%%',\n",
    "                startangle=90, colors=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'])\n",
    "        plt.title('ì‹œì¥ìœ í˜•ë³„ ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 9. í‰ì  vs ë¦¬ë·°ìˆ˜ ì‚°ì ë„\n",
    "    if 'í‰ì ' in df.columns and 'ë¦¬ë·°ìˆ˜' in df.columns:\n",
    "        plt.subplot(3, 3, 9)\n",
    "        valid_data = df[['í‰ì ', 'ë¦¬ë·°ìˆ˜']].dropna()\n",
    "        plt.scatter(valid_data['í‰ì '], valid_data['ë¦¬ë·°ìˆ˜'], alpha=0.6, color='green')\n",
    "        plt.title('í‰ì  vs ë¦¬ë·°ìˆ˜', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('í‰ì ')\n",
    "        plt.ylabel('ë¦¬ë·°ìˆ˜')\n",
    "        \n",
    "        # ì¶”ì„¸ì„  ì¶”ê°€\n",
    "        if len(valid_data) > 1:\n",
    "            z = np.polyfit(valid_data['í‰ì '], valid_data['ë¦¬ë·°ìˆ˜'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(valid_data['í‰ì '], p(valid_data['í‰ì ']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ“ˆ ì‹œê°í™” ë¶„ì„ ì™„ë£Œ!\")\n",
    "\n",
    "# ì‹œê°í™” ì‹¤í–‰\n",
    "create_visualizations(market_df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "# ì‹œì„¤í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ ê°„ì˜ ê´€ê³„ ë¶„ì„\n",
    "\n",
    "def correlation_analysis(df):\n",
    "    \"\"\"ìƒê´€ê´€ê³„ ë¶„ì„ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ” ì‹œì„¤í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ ìƒê´€ê´€ê³„ ë¶„ì„\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ì„ íƒ\n",
    "    numeric_columns = []\n",
    "    \n",
    "    # ì‹œì„¤ ë³´ìœ  ì—¬ë¶€ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "    facility_mapping = {'ìˆìŒ': 1, 'ì—†ìŒ': 0, 'ì •ë³´ì—†ìŒ': 0}\n",
    "    \n",
    "    for col in ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_ìˆ˜ì¹˜'] = df[col].map(facility_mapping)\n",
    "            numeric_columns.append(f'{col}_ìˆ˜ì¹˜')\n",
    "    \n",
    "    # ê¸°ì¡´ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë“¤ ì¶”ê°€\n",
    "    for col in ['ì í¬ìˆ˜', 'í‰ì ', 'ë¦¬ë·°ìˆ˜', 'ìš´ì˜ë…„ìˆ˜']:\n",
    "        if col in df.columns:\n",
    "            numeric_columns.append(col)\n",
    "    \n",
    "    if len(numeric_columns) < 2:\n",
    "        print(\"âŒ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ìƒê´€ê´€ê³„ ê³„ì‚°\n",
    "    correlation_data = df[numeric_columns].corr()\n",
    "    \n",
    "    print(\"ğŸ“Š ì£¼ìš” ìƒê´€ê´€ê³„:\")\n",
    "    \n",
    "    # í‰ì ê³¼ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ìƒê´€ê´€ê³„\n",
    "    if 'í‰ì ' in correlation_data.columns:\n",
    "        rating_corr = correlation_data['í‰ì '].sort_values(ascending=False)\n",
    "        print(\"\\\\nâ­ í‰ì ê³¼ì˜ ìƒê´€ê´€ê³„:\")\n",
    "        for var, corr in rating_corr.items():\n",
    "            if var != 'í‰ì ':\n",
    "                print(f\"   {var}: {corr:.3f}\")\n",
    "    \n",
    "    # ë¦¬ë·°ìˆ˜ì™€ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ìƒê´€ê´€ê³„\n",
    "    if 'ë¦¬ë·°ìˆ˜' in correlation_data.columns:\n",
    "        review_corr = correlation_data['ë¦¬ë·°ìˆ˜'].sort_values(ascending=False)\n",
    "        print(\"\\\\nğŸ’¬ ë¦¬ë·°ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„:\")\n",
    "        for var, corr in review_corr.items():\n",
    "            if var != 'ë¦¬ë·°ìˆ˜':\n",
    "                print(f\"   {var}: {corr:.3f}\")\n",
    "    \n",
    "    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # seabornì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ matplotlibë¡œ ëŒ€ì²´\n",
    "    if 'sns' in globals() and sns is not None:\n",
    "        sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
    "    else:\n",
    "        # matplotlibë¡œ íˆíŠ¸ë§µ êµ¬í˜„\n",
    "        im = plt.imshow(correlation_data.values, cmap='coolwarm', aspect='auto')\n",
    "        plt.colorbar(im, shrink=0.8)\n",
    "        \n",
    "        # ì¶• ë ˆì´ë¸” ì„¤ì •\n",
    "        plt.xticks(range(len(correlation_data.columns)), correlation_data.columns, rotation=45)\n",
    "        plt.yticks(range(len(correlation_data.columns)), correlation_data.columns)\n",
    "        \n",
    "        # ìƒê´€ê³„ìˆ˜ ê°’ í‘œì‹œ\n",
    "        for i in range(len(correlation_data.columns)):\n",
    "            for j in range(len(correlation_data.columns)):\n",
    "                plt.text(j, i, f'{correlation_data.iloc[i, j]:.3f}',\n",
    "                        ha='center', va='center', color='black')\n",
    "    \n",
    "    plt.title('ì‹œì„¤í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ê°•í•œ ìƒê´€ê´€ê³„ ì°¾ê¸°\n",
    "    print(\"\\\\nğŸ”¥ ê°•í•œ ìƒê´€ê´€ê³„ (|r| > 0.3):\")\n",
    "    strong_correlations = []\n",
    "    \n",
    "    for i in range(len(correlation_data.columns)):\n",
    "        for j in range(i+1, len(correlation_data.columns)):\n",
    "            corr_value = correlation_data.iloc[i, j]\n",
    "            if abs(corr_value) > 0.3:\n",
    "                var1 = correlation_data.columns[i]\n",
    "                var2 = correlation_data.columns[j]\n",
    "                strong_correlations.append((var1, var2, corr_value))\n",
    "    \n",
    "    if strong_correlations:\n",
    "        for var1, var2, corr in sorted(strong_correlations, key=lambda x: abs(x[2]), reverse=True):\n",
    "            direction = \"ì–‘ì˜\" if corr > 0 else \"ìŒì˜\"\n",
    "            print(f\"   {var1} â†” {var2}: {corr:.3f} ({direction} ìƒê´€ê´€ê³„)\")\n",
    "    else:\n",
    "        print(\"   ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” ë³€ìˆ˜ ìŒì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰\n",
    "correlation_analysis(market_df_final)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. ë¶„ì„ ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "### 4.1 ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "ë³¸ ë¶„ì„ì„ í†µí•´ ë„ì¶œëœ ì „êµ­ ì „í†µì‹œì¥ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 ì‹¬í™” ë¶„ì„ - ê³ ì„±ê³¼ ì‹œì¥ vs ì €ì„±ê³¼ ì‹œì¥ ë¹„êµ\n",
    "# í‰ì ì„ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„/í•˜ìœ„ ì‹œì¥ë“¤ì˜ íŠ¹ì„± ë¹„êµ\n",
    "\n",
    "def analyze_high_low_performance(df):\n",
    "    \"\"\"ê³ ì„±ê³¼ vs ì €ì„±ê³¼ ì‹œì¥ ë¹„êµ ë¶„ì„\"\"\"\n",
    "    \n",
    "    if df.empty or 'í‰ì ' not in df.columns:\n",
    "        print(\"âŒ ì„±ê³¼ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ† ê³ ì„±ê³¼ vs ì €ì„±ê³¼ ì‹œì¥ ë¹„êµ ë¶„ì„\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # í‰ì  ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 20%, í•˜ìœ„ 20% ì‹œì¥ ì„ ë³„\n",
    "    valid_ratings = df['í‰ì '].dropna()\n",
    "    top_20_threshold = valid_ratings.quantile(0.8)\n",
    "    bottom_20_threshold = valid_ratings.quantile(0.2)\n",
    "    \n",
    "    high_performance = df[df['í‰ì '] >= top_20_threshold]\n",
    "    low_performance = df[df['í‰ì '] <= bottom_20_threshold]\n",
    "    \n",
    "    print(f\"ğŸ“Š ë¶„ì„ ëŒ€ìƒ:\")\n",
    "    print(f\"   ê³ ì„±ê³¼ ì‹œì¥ (ìƒìœ„ 20%): {len(high_performance)}ê°œ (í‰ì  {top_20_threshold:.1f}ì  ì´ìƒ)\")\n",
    "    print(f\"   ì €ì„±ê³¼ ì‹œì¥ (í•˜ìœ„ 20%): {len(low_performance)}ê°œ (í‰ì  {bottom_20_threshold:.1f}ì  ì´í•˜)\")\n",
    "    \n",
    "    # ì‹œì„¤ ë³´ìœ ìœ¨ ë¹„êµ\n",
    "    print(f\"\\\\nğŸ—ï¸ ì‹œì„¤ ë³´ìœ ìœ¨ ë¹„êµ:\")\n",
    "    facilities = ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']\n",
    "    \n",
    "    for facility in facilities:\n",
    "        if facility in df.columns:\n",
    "            high_rate = (high_performance[facility] == 'ìˆìŒ').mean() * 100\n",
    "            low_rate = (low_performance[facility] == 'ìˆìŒ').mean() * 100\n",
    "            diff = high_rate - low_rate\n",
    "            \n",
    "            print(f\"   {facility}:\")\n",
    "            print(f\"     ê³ ì„±ê³¼: {high_rate:.1f}% | ì €ì„±ê³¼: {low_rate:.1f}% | ì°¨ì´: {diff:+.1f}%p\")\n",
    "    \n",
    "    # ì í¬ìˆ˜ ë¹„êµ\n",
    "    if 'ì í¬ìˆ˜' in df.columns:\n",
    "        high_stores = high_performance['ì í¬ìˆ˜'].mean()\n",
    "        low_stores = low_performance['ì í¬ìˆ˜'].mean()\n",
    "        print(f\"\\\\nğŸ¬ í‰ê·  ì í¬ìˆ˜:\")\n",
    "        print(f\"   ê³ ì„±ê³¼: {high_stores:.1f}ê°œ | ì €ì„±ê³¼: {low_stores:.1f}ê°œ\")\n",
    "    \n",
    "    # ìš´ì˜ë…„ìˆ˜ ë¹„êµ\n",
    "    if 'ìš´ì˜ë…„ìˆ˜' in df.columns:\n",
    "        high_age = high_performance['ìš´ì˜ë…„ìˆ˜'].mean()\n",
    "        low_age = low_performance['ìš´ì˜ë…„ìˆ˜'].mean()\n",
    "        print(f\"\\\\nğŸ“… í‰ê·  ìš´ì˜ë…„ìˆ˜:\")\n",
    "        print(f\"   ê³ ì„±ê³¼: {high_age:.1f}ë…„ | ì €ì„±ê³¼: {low_age:.1f}ë…„\")\n",
    "    \n",
    "    # ì§€ì—­ë³„ ë¶„í¬ ë¹„êµ\n",
    "    if 'ì‹œë„' in df.columns:\n",
    "        print(f\"\\\\nğŸ“ ì§€ì—­ë³„ ë¶„í¬ (ìƒìœ„ 5ê°œ ì§€ì—­):\")\n",
    "        print(\"   ê³ ì„±ê³¼ ì‹œì¥:\")\n",
    "        high_regions = high_performance['ì‹œë„'].value_counts().head()\n",
    "        for region, count in high_regions.items():\n",
    "            rate = count / len(high_performance) * 100\n",
    "            print(f\"     {region}: {count}ê°œ ({rate:.1f}%)\")\n",
    "        \n",
    "        print(\"   ì €ì„±ê³¼ ì‹œì¥:\")\n",
    "        low_regions = low_performance['ì‹œë„'].value_counts().head()\n",
    "        for region, count in low_regions.items():\n",
    "            rate = count / len(low_performance) * 100\n",
    "            print(f\"     {region}: {count}ê°œ ({rate:.1f}%)\")\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. ì‹œì„¤ ë³´ìœ ìœ¨ ë¹„êµ\n",
    "    ax1 = axes[0, 0]\n",
    "    facility_comparison = []\n",
    "    labels = []\n",
    "    \n",
    "    for facility in facilities:\n",
    "        if facility in df.columns:\n",
    "            high_rate = (high_performance[facility] == 'ìˆìŒ').mean() * 100\n",
    "            low_rate = (low_performance[facility] == 'ìˆìŒ').mean() * 100\n",
    "            facility_comparison.append([high_rate, low_rate])\n",
    "            labels.append(facility)\n",
    "    \n",
    "    if facility_comparison:\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        high_rates = [item[0] for item in facility_comparison]\n",
    "        low_rates = [item[1] for item in facility_comparison]\n",
    "        \n",
    "        ax1.bar(x - width/2, high_rates, width, label='ê³ ì„±ê³¼', color='lightgreen')\n",
    "        ax1.bar(x + width/2, low_rates, width, label='ì €ì„±ê³¼', color='lightcoral')\n",
    "        \n",
    "        ax1.set_xlabel('ì‹œì„¤ ìœ í˜•')\n",
    "        ax1.set_ylabel('ë³´ìœ ìœ¨ (%)')\n",
    "        ax1.set_title('ì‹œì„¤ ë³´ìœ ìœ¨ ë¹„êµ')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(labels)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. ì í¬ìˆ˜ ë¶„í¬ ë¹„êµ\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'ì í¬ìˆ˜' in df.columns:\n",
    "        high_stores = high_performance['ì í¬ìˆ˜'].dropna()\n",
    "        low_stores = low_performance['ì í¬ìˆ˜'].dropna()\n",
    "        \n",
    "        ax2.hist(high_stores, bins=20, alpha=0.7, label='ê³ ì„±ê³¼', color='lightgreen')\n",
    "        ax2.hist(low_stores, bins=20, alpha=0.7, label='ì €ì„±ê³¼', color='lightcoral')\n",
    "        ax2.set_xlabel('ì í¬ìˆ˜')\n",
    "        ax2.set_ylabel('ì‹œì¥ ìˆ˜')\n",
    "        ax2.set_title('ì í¬ìˆ˜ ë¶„í¬ ë¹„êµ')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. í‰ì  ë¶„í¬\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.hist(high_performance['í‰ì '], bins=15, alpha=0.7, label='ê³ ì„±ê³¼', color='lightgreen')\n",
    "    ax3.hist(low_performance['í‰ì '], bins=15, alpha=0.7, label='ì €ì„±ê³¼', color='lightcoral')\n",
    "    ax3.set_xlabel('í‰ì ')\n",
    "    ax3.set_ylabel('ì‹œì¥ ìˆ˜')\n",
    "    ax3.set_title('í‰ì  ë¶„í¬')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. ë¦¬ë·°ìˆ˜ ë¶„í¬\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'ë¦¬ë·°ìˆ˜' in df.columns:\n",
    "        high_reviews = high_performance['ë¦¬ë·°ìˆ˜'].dropna()\n",
    "        low_reviews = low_performance['ë¦¬ë·°ìˆ˜'].dropna()\n",
    "        \n",
    "        ax4.hist(high_reviews, bins=20, alpha=0.7, label='ê³ ì„±ê³¼', color='lightgreen')\n",
    "        ax4.hist(low_reviews, bins=20, alpha=0.7, label='ì €ì„±ê³¼', color='lightcoral')\n",
    "        ax4.set_xlabel('ë¦¬ë·°ìˆ˜')\n",
    "        ax4.set_ylabel('ì‹œì¥ ìˆ˜')\n",
    "        ax4.set_title('ë¦¬ë·°ìˆ˜ ë¶„í¬ ë¹„êµ')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return high_performance, low_performance\n",
    "\n",
    "# ê³ ì„±ê³¼ vs ì €ì„±ê³¼ ë¶„ì„ ì‹¤í–‰\n",
    "high_perf_markets, low_perf_markets = analyze_high_low_performance(market_df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 í‚¤ì›Œë“œ ë¶„ì„ ë° ì›Œë“œí´ë¼ìš°ë“œ\n",
    "# ë¦¬ë·° í‚¤ì›Œë“œ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜\n",
    "\n",
    "def keyword_analysis_simulation(df):\n",
    "    \"\"\"í‚¤ì›Œë“œ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”¤ ì „í†µì‹œì¥ ë¦¬ë·° í‚¤ì›Œë“œ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ì „í†µì‹œì¥ ê´€ë ¨ í‚¤ì›Œë“œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°\n",
    "    positive_keywords = [\n",
    "        'ë§›ìˆë‹¤', 'ì‹ ì„ í•˜ë‹¤', 'ì €ë ´í•˜ë‹¤', 'ì¹œì ˆí•˜ë‹¤', 'ê¹¨ë—í•˜ë‹¤', 'ë‹¤ì–‘í•˜ë‹¤',\n",
    "        'ì „í†µì ì´ë‹¤', 'ì •ê²¨ì›ë‹¤', 'í™œê¸°ì°¨ë‹¤', 'í¸ë¦¬í•˜ë‹¤', 'ì¢‹ë‹¤', 'ë§Œì¡±í•˜ë‹¤',\n",
    "        'ì¶”ì²œí•œë‹¤', 'ì¬ë°©ë¬¸', 'í’ˆì§ˆì¢‹ë‹¤', 'ê°€ì„±ë¹„', 'ë¶„ìœ„ê¸°ì¢‹ë‹¤', 'ì ‘ê·¼ì„±ì¢‹ë‹¤'\n",
    "    ]\n",
    "    \n",
    "    negative_keywords = [\n",
    "        'ë¹„ì‹¸ë‹¤', 'ë¶ˆì¹œì ˆí•˜ë‹¤', 'ë”ëŸ½ë‹¤', 'ì˜¤ë˜ë˜ë‹¤', 'ë¶ˆí¸í•˜ë‹¤', 'ì‹œë„ëŸ½ë‹¤',\n",
    "        'ì£¼ì°¨ì–´ë µë‹¤', 'ëƒ„ìƒˆë‚œë‹¤', 'ì¢ë‹¤', 'ë³µì¡í•˜ë‹¤', 'ì•„ì‰½ë‹¤', 'ê°œì„ í•„ìš”',\n",
    "        'í™”ì¥ì‹¤ë”ëŸ½ë‹¤', 'ì ‘ê·¼ì–´ë µë‹¤', 'ì‹œì„¤ë‚¡ë‹¤', 'ê´€ë¦¬ë¶€ì¡±'\n",
    "    ]\n",
    "    \n",
    "    facility_keywords = [\n",
    "        'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤', 'ì•„ì¼€ì´ë“œ', 'ì—ì–´ì»¨', 'ë‚œë°©', 'ì¡°ëª…', 'ì•ˆì „',\n",
    "        'ì ‘ê·¼ì„±', 'êµí†µ', 'ì§€í•˜ì² ', 'ë²„ìŠ¤', 'íƒì‹œ', 'ì—˜ë¦¬ë² ì´í„°', 'ê³„ë‹¨'\n",
    "    ]\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ë¹ˆë„ ì‹œë®¬ë ˆì´ì…˜ (í‰ì ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    keyword_freq = {}\n",
    "    \n",
    "    # ê¸ì • í‚¤ì›Œë“œ (í‰ì ì´ ë†’ì„ìˆ˜ë¡ ë¹ˆë„ ì¦ê°€)\n",
    "    for keyword in positive_keywords:\n",
    "        base_freq = np.random.randint(50, 200)\n",
    "        # í‰ì  í‰ê· ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "        if 'í‰ì ' in df.columns:\n",
    "            avg_rating = df['í‰ì '].mean()\n",
    "            weight = avg_rating / 5.0\n",
    "            keyword_freq[keyword] = int(base_freq * weight)\n",
    "        else:\n",
    "            keyword_freq[keyword] = base_freq\n",
    "    \n",
    "    # ë¶€ì • í‚¤ì›Œë“œ (í‰ì ì´ ë‚®ì„ìˆ˜ë¡ ë¹ˆë„ ì¦ê°€)\n",
    "    for keyword in negative_keywords:\n",
    "        base_freq = np.random.randint(20, 80)\n",
    "        if 'í‰ì ' in df.columns:\n",
    "            avg_rating = df['í‰ì '].mean()\n",
    "            weight = (5.0 - avg_rating) / 5.0\n",
    "            keyword_freq[keyword] = int(base_freq * weight)\n",
    "        else:\n",
    "            keyword_freq[keyword] = base_freq\n",
    "    \n",
    "    # ì‹œì„¤ ê´€ë ¨ í‚¤ì›Œë“œ\n",
    "    for keyword in facility_keywords:\n",
    "        keyword_freq[keyword] = np.random.randint(30, 120)\n",
    "    \n",
    "    # ìƒìœ„ í‚¤ì›Œë“œ ì¶œë ¥\n",
    "    sorted_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"ğŸ“Š ì£¼ìš” í‚¤ì›Œë“œ TOP 20:\")\n",
    "    for i, (keyword, freq) in enumerate(sorted_keywords[:20], 1):\n",
    "        print(f\"   {i:2d}. {keyword}: {freq}íšŒ\")\n",
    "    \n",
    "    # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ë¹„ìœ¨\n",
    "    positive_total = sum(freq for keyword, freq in keyword_freq.items() if keyword in positive_keywords)\n",
    "    negative_total = sum(freq for keyword, freq in keyword_freq.items() if keyword in negative_keywords)\n",
    "    total_sentiment = positive_total + negative_total\n",
    "    \n",
    "    if total_sentiment > 0:\n",
    "        positive_ratio = positive_total / total_sentiment * 100\n",
    "        negative_ratio = negative_total / total_sentiment * 100\n",
    "        \n",
    "        print(f\"\\\\nğŸ˜Š ê°ì • ë¶„ì„ ê²°ê³¼:\")\n",
    "        print(f\"   ê¸ì • í‚¤ì›Œë“œ: {positive_ratio:.1f}% ({positive_total}íšŒ)\")\n",
    "        print(f\"   ë¶€ì • í‚¤ì›Œë“œ: {negative_ratio:.1f}% ({negative_total}íšŒ)\")\n",
    "    \n",
    "    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±\n",
    "    create_wordcloud_visualization(keyword_freq)\n",
    "    \n",
    "    return keyword_freq\n",
    "\n",
    "def create_wordcloud_visualization(keyword_freq):\n",
    "    \"\"\"ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # WordCloud ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©\n",
    "    if 'WordCloud' in globals() and WordCloud is not None:\n",
    "        try:\n",
    "            # í•œê¸€ í°íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "            font_paths = [\n",
    "                'C:/Windows/Fonts/malgun.ttf',  # Windows\n",
    "                '/System/Library/Fonts/AppleGothic.ttf',  # macOS\n",
    "                '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'  # Linux\n",
    "            ]\n",
    "            \n",
    "            font_path = None\n",
    "            for path in font_paths:\n",
    "                try:\n",
    "                    with open(path, 'rb'):\n",
    "                        font_path = path\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±\n",
    "            wordcloud = WordCloud(\n",
    "                width=800, height=400,\n",
    "                background_color='white',\n",
    "                font_path=font_path,\n",
    "                max_words=100,\n",
    "                colormap='viridis'\n",
    "            ).generate_from_frequencies(keyword_freq)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title('ì „í†µì‹œì¥ ë¦¬ë·° í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ', fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì™„ë£Œ!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            create_alternative_keyword_visualization(keyword_freq)\n",
    "    else:\n",
    "        print(\"âš ï¸ WordCloud ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ì‹œê°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        create_alternative_keyword_visualization(keyword_freq)\n",
    "\n",
    "def create_alternative_keyword_visualization(keyword_freq):\n",
    "    \"\"\"ì›Œë“œí´ë¼ìš°ë“œ ëŒ€ì²´ ì‹œê°í™”\"\"\"\n",
    "    \n",
    "    # ìƒìœ„ 15ê°œ í‚¤ì›Œë“œë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±\n",
    "    sorted_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "    keywords, frequencies = zip(*sorted_keywords)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(range(len(keywords)), frequencies, color='skyblue')\n",
    "    plt.yticks(range(len(keywords)), keywords)\n",
    "    plt.xlabel('ë¹ˆë„')\n",
    "    plt.title('ì „í†µì‹œì¥ ë¦¬ë·° ì£¼ìš” í‚¤ì›Œë“œ (TOP 15)', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # ë§‰ëŒ€ì— ê°’ í‘œì‹œ\n",
    "    for i, (bar, freq) in enumerate(zip(bars, frequencies)):\n",
    "        plt.text(freq + max(frequencies) * 0.01, i, str(freq), \n",
    "                va='center', ha='left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ“Š í‚¤ì›Œë“œ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "# í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰\n",
    "keyword_results = keyword_analysis_simulation(market_df_final)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. ì •ì±… ì œì•ˆ\n",
    "\n",
    "### 5.1 ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì •ì±… ì œì•ˆ\n",
    "ì „í†µì‹œì¥ í™œì„±í™”ë¥¼ ìœ„í•œ ë‹¨ê³„ë³„ ì •ì±… ì œì•ˆì‚¬í•­ì„ ì œì‹œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 ì •ì±… ì œì•ˆ ìƒì„± ë° ìš°ì„ ìˆœìœ„ ë¶„ì„\n",
    "\n",
    "def generate_policy_recommendations(df, high_perf, low_perf, keyword_freq):\n",
    "    \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ì±… ì œì•ˆ ìƒì„±\"\"\"\n",
    "    \n",
    "    print(\"ğŸ›ï¸ ì „í†µì‹œì¥ í™œì„±í™” ì •ì±… ì œì•ˆ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. ë‹¨ê¸° ì •ì±… (1ë…„ ì´ë‚´)\n",
    "    print(\"\\\\nğŸ“… ë‹¨ê¸° ì •ì±… ì œì•ˆ (1ë…„ ì´ë‚´)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    short_term_policies = [\n",
    "        {\n",
    "            \"ì œëª©\": \"ì‹œì„¤ ê°œì„  ìš°ì„ ìˆœìœ„ ì§€ì›\",\n",
    "            \"ë‚´ìš©\": \"ì£¼ì°¨ì¥, í™”ì¥ì‹¤, ì•„ì¼€ì´ë“œ ë“± ê¸°ë³¸ ì‹œì„¤ ê°œì„  ì§€ì›\",\n",
    "            \"ê·¼ê±°\": \"ê³ ì„±ê³¼ ì‹œì¥ì˜ ì‹œì„¤ ë³´ìœ ìœ¨ì´ ì €ì„±ê³¼ ì‹œì¥ë³´ë‹¤ ë†’ìŒ\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ í‰ê·  5,000ë§Œì›\",\n",
    "            \"ëŒ€ìƒ\": \"ì‹œì„¤ ë³´ìœ ìœ¨ì´ ë‚®ì€ í•˜ìœ„ 30% ì‹œì¥\"\n",
    "        },\n",
    "        {\n",
    "            \"ì œëª©\": \"ë””ì§€í„¸ ë§ˆì¼€íŒ… ì§€ì›\",\n",
    "            \"ë‚´ìš©\": \"ì˜¨ë¼ì¸ ë¦¬ë·° ê´€ë¦¬ ë° SNS ë§ˆì¼€íŒ… êµìœ¡ í”„ë¡œê·¸ë¨\",\n",
    "            \"ê·¼ê±°\": \"ë¦¬ë·° ìˆ˜ì™€ í‰ì ì´ ì‹œì¥ ì„±ê³¼ì™€ ìƒê´€ê´€ê³„ ìˆìŒ\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ í‰ê·  500ë§Œì›\",\n",
    "            \"ëŒ€ìƒ\": \"ë¦¬ë·° ìˆ˜ê°€ ì ì€ ì‹œì¥ ìš°ì„ \"\n",
    "        },\n",
    "        {\n",
    "            \"ì œëª©\": \"ì²­ê²°ë„ ê°œì„  ìº í˜ì¸\",\n",
    "            \"ë‚´ìš©\": \"ì •ê¸°ì ì¸ ì²­ì†Œ ë° ìœ„ìƒ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•\",\n",
    "            \"ê·¼ê±°\": \"í‚¤ì›Œë“œ ë¶„ì„ì—ì„œ 'ê¹¨ë—í•˜ë‹¤'ê°€ ê¸ì • ìš”ì¸ìœ¼ë¡œ ë‚˜íƒ€ë‚¨\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ ì›” 200ë§Œì›\",\n",
    "            \"ëŒ€ìƒ\": \"ì „ì²´ ì‹œì¥ ëŒ€ìƒ\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, policy in enumerate(short_term_policies, 1):\n",
    "        print(f\"\\\\n{i}. {policy['ì œëª©']}\")\n",
    "        print(f\"   ğŸ“‹ ë‚´ìš©: {policy['ë‚´ìš©']}\")\n",
    "        print(f\"   ğŸ“Š ê·¼ê±°: {policy['ê·¼ê±°']}\")\n",
    "        print(f\"   ğŸ’° ì˜ˆì‚°: {policy['ì˜ˆì‚°']}\")\n",
    "        print(f\"   ğŸ¯ ëŒ€ìƒ: {policy['ëŒ€ìƒ']}\")\n",
    "    \n",
    "    # 2. ì¤‘ê¸° ì •ì±… (2-3ë…„)\n",
    "    print(\"\\\\n\\\\nğŸ“… ì¤‘ê¸° ì •ì±… ì œì•ˆ (2-3ë…„)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    medium_term_policies = [\n",
    "        {\n",
    "            \"ì œëª©\": \"ìŠ¤ë§ˆíŠ¸ ì „í†µì‹œì¥ êµ¬ì¶•\",\n",
    "            \"ë‚´ìš©\": \"IoT, í‚¤ì˜¤ìŠ¤í¬, ëª¨ë°”ì¼ ê²°ì œ ì‹œìŠ¤í…œ ë„ì…\",\n",
    "            \"ê·¼ê±°\": \"ì ‘ê·¼ì„±ê³¼ í¸ë¦¬ì„±ì´ ê³ ê° ë§Œì¡±ë„ì— ì˜í–¥\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ í‰ê·  2ì–µì›\",\n",
    "            \"ëŒ€ìƒ\": \"ì¤‘ëŒ€í˜• ì‹œì¥ ìš°ì„  (ì í¬ìˆ˜ 100ê°œ ì´ìƒ)\"\n",
    "        },\n",
    "        {\n",
    "            \"ì œëª©\": \"ì§€ì—­ íŠ¹í™” ìƒí’ˆ ê°œë°œ\",\n",
    "            \"ë‚´ìš©\": \"ì§€ì—­ë³„ íŠ¹ì‚°í’ˆì„ í™œìš©í•œ ë¸Œëœë“œ ìƒí’ˆ ê°œë°œ\",\n",
    "            \"ê·¼ê±°\": \"ì§€ì—­ë³„ ì‹œì¥ ì„±ê³¼ ì°¨ì´ ì¡´ì¬\",\n",
    "            \"ì˜ˆì‚°\": \"ì§€ì—­ë‹¹ í‰ê·  1ì–µì›\",\n",
    "            \"ëŒ€ìƒ\": \"ì§€ì—­ ëŒ€í‘œ ì‹œì¥ ì„ ì •\"\n",
    "        },\n",
    "        {\n",
    "            \"ì œëª©\": \"êµí†µ ì ‘ê·¼ì„± ê°œì„ \",\n",
    "            \"ë‚´ìš©\": \"ëŒ€ì¤‘êµí†µ ì—°ê³„ ë° ì£¼ì°¨ ì‹œì„¤ í™•ì¶©\",\n",
    "            \"ê·¼ê±°\": \"ì ‘ê·¼ì„±ì´ ì‹œì¥ ì´ìš©ë¥ ì— ì§ì ‘ì  ì˜í–¥\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ í‰ê·  3ì–µì›\",\n",
    "            \"ëŒ€ìƒ\": \"êµí†µ ë¶ˆí¸ ì§€ì—­ ì‹œì¥ ìš°ì„ \"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, policy in enumerate(medium_term_policies, 1):\n",
    "        print(f\"\\\\n{i}. {policy['ì œëª©']}\")\n",
    "        print(f\"   ğŸ“‹ ë‚´ìš©: {policy['ë‚´ìš©']}\")\n",
    "        print(f\"   ğŸ“Š ê·¼ê±°: {policy['ê·¼ê±°']}\")\n",
    "        print(f\"   ğŸ’° ì˜ˆì‚°: {policy['ì˜ˆì‚°']}\")\n",
    "        print(f\"   ğŸ¯ ëŒ€ìƒ: {policy['ëŒ€ìƒ']}\")\n",
    "    \n",
    "    # 3. ì¥ê¸° ì •ì±… (3-5ë…„)\n",
    "    print(\"\\\\n\\\\nğŸ“… ì¥ê¸° ì •ì±… ì œì•ˆ (3-5ë…„)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    long_term_policies = [\n",
    "        {\n",
    "            \"ì œëª©\": \"ì „í†µì‹œì¥ ë³µí•©ë¬¸í™”ê³µê°„ ì¡°ì„±\",\n",
    "            \"ë‚´ìš©\": \"ì‡¼í•‘, ë¬¸í™”, ì²´í—˜ì´ ê²°í•©ëœ ë³µí•©ê³µê°„ìœ¼ë¡œ ì¬êµ¬ì„±\",\n",
    "            \"ê·¼ê±°\": \"ì „í†µì  ê°€ì¹˜ì™€ í˜„ëŒ€ì  í¸ì˜ì„±ì˜ ì¡°í™” í•„ìš”\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ í‰ê·  10ì–µì›\",\n",
    "            \"ëŒ€ìƒ\": \"ì—­ì‚¬ì„±ê³¼ ì ì¬ë ¥ì´ ë†’ì€ ëŒ€í‘œ ì‹œì¥\"\n",
    "        },\n",
    "        {\n",
    "            \"ì œëª©\": \"ì„¸ëŒ€ ê°„ ìƒì¸ ìœ¡ì„± í”„ë¡œê·¸ë¨\",\n",
    "            \"ë‚´ìš©\": \"ì Šì€ ìƒì¸ ìœ ì… ë° ê¸°ì¡´ ìƒì¸ê³¼ì˜ ë©˜í† ë§ ì‹œìŠ¤í…œ\",\n",
    "            \"ê·¼ê±°\": \"ìš´ì˜ë…„ìˆ˜ì™€ í˜ì‹ ì„±ì˜ ê· í˜• í•„ìš”\",\n",
    "            \"ì˜ˆì‚°\": \"ì—°ê°„ 50ì–µì› (ì „êµ­ ë‹¨ìœ„)\",\n",
    "            \"ëŒ€ìƒ\": \"ì „ì²´ ì‹œì¥ ëŒ€ìƒ\"\n",
    "        },\n",
    "        {\n",
    "            \"ì œëª©\": \"ê¸€ë¡œë²Œ ê´€ê´‘ ëª…ì†Œí™”\",\n",
    "            \"ë‚´ìš©\": \"ì™¸êµ­ì¸ ê´€ê´‘ê° ëŒ€ìƒ K-ë§ˆì¼“ ë¸Œëœë“œ êµ¬ì¶•\",\n",
    "            \"ê·¼ê±°\": \"ë¬¸í™” ê´€ê´‘ ìì›ìœ¼ë¡œì„œì˜ ê°€ì¹˜ í™œìš©\",\n",
    "            \"ì˜ˆì‚°\": \"ì‹œì¥ë‹¹ í‰ê·  5ì–µì›\",\n",
    "            \"ëŒ€ìƒ\": \"ê´€ê´‘ì§€ ì¸ê·¼ ëŒ€í˜• ì‹œì¥\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, policy in enumerate(long_term_policies, 1):\n",
    "        print(f\"\\\\n{i}. {policy['ì œëª©']}\")\n",
    "        print(f\"   ğŸ“‹ ë‚´ìš©: {policy['ë‚´ìš©']}\")\n",
    "        print(f\"   ğŸ“Š ê·¼ê±°: {policy['ê·¼ê±°']}\")\n",
    "        print(f\"   ğŸ’° ì˜ˆì‚°: {policy['ì˜ˆì‚°']}\")\n",
    "        print(f\"   ğŸ¯ ëŒ€ìƒ: {policy['ëŒ€ìƒ']}\")\n",
    "    \n",
    "    # 4. ìš°ì„ ìˆœìœ„ ì‹œì¥ ì„ ì •\n",
    "    print(\"\\\\n\\\\nğŸ¯ ìš°ì„  ì§€ì› ëŒ€ìƒ ì‹œì¥ ì„ ì •\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if not df.empty:\n",
    "        # ê°œì„  ì ì¬ë ¥ì´ ë†’ì€ ì‹œì¥ ì„ ì • (í˜„ì¬ ì„±ê³¼ëŠ” ë‚®ì§€ë§Œ ê¸°ë³¸ ì¡°ê±´ì´ ì¢‹ì€ ì‹œì¥)\n",
    "        priority_markets = identify_priority_markets(df)\n",
    "        \n",
    "        print(\"\\\\nğŸ“Š ìš°ì„  ì§€ì› ëŒ€ìƒ ì‹œì¥ (ìƒìœ„ 10ê°œ):\")\n",
    "        for i, (market_name, score, reason) in enumerate(priority_markets[:10], 1):\n",
    "            print(f\"   {i:2d}. {market_name} (ì ìˆ˜: {score:.2f})\")\n",
    "            print(f\"       ì‚¬ìœ : {reason}\")\n",
    "    \n",
    "    # 5. ì˜ˆìƒ íš¨ê³¼ ë° ì„±ê³¼ ì§€í‘œ\n",
    "    print(\"\\\\n\\\\nğŸ“ˆ ì˜ˆìƒ íš¨ê³¼ ë° ì„±ê³¼ ì§€í‘œ\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    expected_effects = [\n",
    "        \"í‰ê·  í‰ì  0.5ì  í–¥ìƒ (í˜„ì¬ ëŒ€ë¹„ 15% ì¦ê°€)\",\n",
    "        \"ë¦¬ë·° ìˆ˜ 30% ì¦ê°€ (ì˜¨ë¼ì¸ ì¸ì§€ë„ í–¥ìƒ)\",\n",
    "        \"ì‹œì„¤ ë³´ìœ ìœ¨ 20%p í–¥ìƒ\",\n",
    "        \"ë°©ë¬¸ê° ìˆ˜ 25% ì¦ê°€\",\n",
    "        \"ë§¤ì¶œì•¡ 20% ì¦ê°€\",\n",
    "        \"ìƒì¸ ë§Œì¡±ë„ 30% í–¥ìƒ\"\n",
    "    ]\n",
    "    \n",
    "    for i, effect in enumerate(expected_effects, 1):\n",
    "        print(f\"   {i}. {effect}\")\n",
    "    \n",
    "    print(\"\\\\nâœ… ì •ì±… ì œì•ˆ ì™„ë£Œ!\")\n",
    "\n",
    "def identify_priority_markets(df):\n",
    "    \"\"\"ìš°ì„  ì§€ì› ëŒ€ìƒ ì‹œì¥ ì‹ë³„\"\"\"\n",
    "    \n",
    "    priority_list = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        score = 0\n",
    "        reasons = []\n",
    "        \n",
    "        market_name = row.get('ì‹œì¥ëª…', f'ì‹œì¥_{idx}')\n",
    "        \n",
    "        # ì í¬ìˆ˜ê°€ ë§ìœ¼ë©´ ê°€ì  (ê·œëª¨ì˜ ê²½ì œ)\n",
    "        if 'ì í¬ìˆ˜' in row and pd.notna(row['ì í¬ìˆ˜']):\n",
    "            if row['ì í¬ìˆ˜'] > 100:\n",
    "                score += 2\n",
    "                reasons.append(\"ëŒ€ê·œëª¨ ì‹œì¥\")\n",
    "            elif row['ì í¬ìˆ˜'] > 50:\n",
    "                score += 1\n",
    "                reasons.append(\"ì¤‘ê·œëª¨ ì‹œì¥\")\n",
    "        \n",
    "        # í‰ì ì´ ì¤‘ê°„ ì •ë„ë©´ ê°€ì  (ê°œì„  ì—¬ì§€)\n",
    "        if 'í‰ì ' in row and pd.notna(row['í‰ì ']):\n",
    "            if 3.0 <= row['í‰ì '] <= 4.0:\n",
    "                score += 2\n",
    "                reasons.append(\"ê°œì„  ì ì¬ë ¥\")\n",
    "            elif row['í‰ì '] < 3.0:\n",
    "                score += 1\n",
    "                reasons.append(\"ê°œì„  í•„ìš”\")\n",
    "        \n",
    "        # ì‹œì„¤ì´ ë¶€ì¡±í•˜ë©´ ê°€ì  (ê°œì„  íš¨ê³¼ í´ ê²ƒìœ¼ë¡œ ì˜ˆìƒ)\n",
    "        facility_score = 0\n",
    "        for facility in ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']:\n",
    "            if facility in row and row[facility] == 'ì—†ìŒ':\n",
    "                facility_score += 1\n",
    "        \n",
    "        if facility_score >= 2:\n",
    "            score += 2\n",
    "            reasons.append(\"ì‹œì„¤ ê°œì„  í•„ìš”\")\n",
    "        elif facility_score == 1:\n",
    "            score += 1\n",
    "            reasons.append(\"ì¼ë¶€ ì‹œì„¤ ê°œì„  í•„ìš”\")\n",
    "        \n",
    "        # ìš´ì˜ë…„ìˆ˜ê°€ ì ë‹¹í•˜ë©´ ê°€ì  (ë„ˆë¬´ ì˜¤ë˜ë˜ì§€ë„ ìƒˆë¡­ì§€ë„ ì•Šì€)\n",
    "        if 'ìš´ì˜ë…„ìˆ˜' in row and pd.notna(row['ìš´ì˜ë…„ìˆ˜']):\n",
    "            if 10 <= row['ìš´ì˜ë…„ìˆ˜'] <= 30:\n",
    "                score += 1\n",
    "                reasons.append(\"ì ì • ìš´ì˜ ê²½í—˜\")\n",
    "        \n",
    "        if score > 0:\n",
    "            reason_text = \", \".join(reasons)\n",
    "            priority_list.append((market_name, score, reason_text))\n",
    "    \n",
    "    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    priority_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return priority_list\n",
    "\n",
    "# ì •ì±… ì œì•ˆ ìƒì„±\n",
    "generate_policy_recommendations(market_df_final, high_perf_markets, low_perf_markets, keyword_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 ë°ì´í„° ì €ì¥ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "# ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "\n",
    "def save_analysis_results(df, high_perf, low_perf, keyword_freq):\n",
    "    \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "    \n",
    "    print(\"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. ì „ì²´ ë¶„ì„ ë°ì´í„° ì €ì¥\n",
    "        if not df.empty:\n",
    "            df.to_csv('ì „í†µì‹œì¥_ë¶„ì„ê²°ê³¼_ì „ì²´.csv', index=False, encoding='utf-8-sig')\n",
    "            print(\"âœ… ì „ì²´ ë¶„ì„ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ì „í†µì‹œì¥_ë¶„ì„ê²°ê³¼_ì „ì²´.csv\")\n",
    "        \n",
    "        # 2. ê³ ì„±ê³¼ ì‹œì¥ ë°ì´í„° ì €ì¥\n",
    "        if not high_perf.empty:\n",
    "            high_perf.to_csv('ì „í†µì‹œì¥_ê³ ì„±ê³¼ì‹œì¥.csv', index=False, encoding='utf-8-sig')\n",
    "            print(\"âœ… ê³ ì„±ê³¼ ì‹œì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ì „í†µì‹œì¥_ê³ ì„±ê³¼ì‹œì¥.csv\")\n",
    "        \n",
    "        # 3. ì €ì„±ê³¼ ì‹œì¥ ë°ì´í„° ì €ì¥\n",
    "        if not low_perf.empty:\n",
    "            low_perf.to_csv('ì „í†µì‹œì¥_ì €ì„±ê³¼ì‹œì¥.csv', index=False, encoding='utf-8-sig')\n",
    "            print(\"âœ… ì €ì„±ê³¼ ì‹œì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ì „í†µì‹œì¥_ì €ì„±ê³¼ì‹œì¥.csv\")\n",
    "        \n",
    "        # 4. í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "        if keyword_freq:\n",
    "            keyword_df = pd.DataFrame(list(keyword_freq.items()), columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])\n",
    "            keyword_df = keyword_df.sort_values('ë¹ˆë„', ascending=False)\n",
    "            keyword_df.to_csv('ì „í†µì‹œì¥_í‚¤ì›Œë“œë¶„ì„.csv', index=False, encoding='utf-8-sig')\n",
    "            print(\"âœ… í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ì „í†µì‹œì¥_í‚¤ì›Œë“œë¶„ì„.csv\")\n",
    "        \n",
    "        # 5. ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±\n",
    "        create_summary_report(df, high_perf, low_perf, keyword_freq)\n",
    "        \n",
    "        print(\"\\\\nğŸ“Š ì €ì¥ëœ íŒŒì¼ ëª©ë¡:\")\n",
    "        print(\"   1. ì „í†µì‹œì¥_ë¶„ì„ê²°ê³¼_ì „ì²´.csv - ì „ì²´ ë¶„ì„ ë°ì´í„°\")\n",
    "        print(\"   2. ì „í†µì‹œì¥_ê³ ì„±ê³¼ì‹œì¥.csv - ìƒìœ„ 20% ì‹œì¥ ë°ì´í„°\")\n",
    "        print(\"   3. ì „í†µì‹œì¥_ì €ì„±ê³¼ì‹œì¥.csv - í•˜ìœ„ 20% ì‹œì¥ ë°ì´í„°\")\n",
    "        print(\"   4. ì „í†µì‹œì¥_í‚¤ì›Œë“œë¶„ì„.csv - ë¦¬ë·° í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼\")\n",
    "        print(\"   5. ì „í†µì‹œì¥_ë¶„ì„ìš”ì•½ë³´ê³ ì„œ.csv - ì£¼ìš” í†µê³„ ìš”ì•½\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "def create_summary_report(df, high_perf, low_perf, keyword_freq):\n",
    "    \"\"\"ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    # ê¸°ë³¸ í†µê³„\n",
    "    if not df.empty:\n",
    "        summary_data.append(['ì „ì²´ ì‹œì¥ ìˆ˜', len(df)])\n",
    "        \n",
    "        if 'í‰ì ' in df.columns:\n",
    "            summary_data.append(['í‰ê·  í‰ì ', f\"{df['í‰ì '].mean():.2f}\"])\n",
    "            summary_data.append(['ìµœê³  í‰ì ', f\"{df['í‰ì '].max():.1f}\"])\n",
    "            summary_data.append(['ìµœì € í‰ì ', f\"{df['í‰ì '].min():.1f}\"])\n",
    "        \n",
    "        if 'ë¦¬ë·°ìˆ˜' in df.columns:\n",
    "            summary_data.append(['í‰ê·  ë¦¬ë·°ìˆ˜', f\"{df['ë¦¬ë·°ìˆ˜'].mean():.1f}\"])\n",
    "            summary_data.append(['ìµœëŒ€ ë¦¬ë·°ìˆ˜', f\"{df['ë¦¬ë·°ìˆ˜'].max():.0f}\"])\n",
    "        \n",
    "        if 'ì í¬ìˆ˜' in df.columns:\n",
    "            summary_data.append(['í‰ê·  ì í¬ìˆ˜', f\"{df['ì í¬ìˆ˜'].mean():.1f}\"])\n",
    "            summary_data.append(['ìµœëŒ€ ì í¬ìˆ˜', f\"{df['ì í¬ìˆ˜'].max():.0f}\"])\n",
    "        \n",
    "        # ì‹œì„¤ ë³´ìœ ìœ¨\n",
    "        for facility in ['ì•„ì¼€ì´ë“œ', 'ì£¼ì°¨ì¥', 'í™”ì¥ì‹¤']:\n",
    "            if facility in df.columns:\n",
    "                rate = (df[facility] == 'ìˆìŒ').mean() * 100\n",
    "                summary_data.append([f'{facility} ë³´ìœ ìœ¨', f\"{rate:.1f}%\"])\n",
    "        \n",
    "        # ì§€ì—­ë³„ ë¶„í¬\n",
    "        if 'ì‹œë„' in df.columns:\n",
    "            top_region = df['ì‹œë„'].value_counts().index[0]\n",
    "            top_count = df['ì‹œë„'].value_counts().iloc[0]\n",
    "            summary_data.append(['ìµœë‹¤ ì‹œì¥ ì§€ì—­', f\"{top_region} ({top_count}ê°œ)\"])\n",
    "    \n",
    "    # ê³ ì„±ê³¼ vs ì €ì„±ê³¼ ë¹„êµ\n",
    "    if not high_perf.empty and not low_perf.empty:\n",
    "        summary_data.append(['ê³ ì„±ê³¼ ì‹œì¥ ìˆ˜', len(high_perf)])\n",
    "        summary_data.append(['ì €ì„±ê³¼ ì‹œì¥ ìˆ˜', len(low_perf)])\n",
    "        \n",
    "        if 'í‰ì ' in high_perf.columns and 'í‰ì ' in low_perf.columns:\n",
    "            high_avg = high_perf['í‰ì '].mean()\n",
    "            low_avg = low_perf['í‰ì '].mean()\n",
    "            summary_data.append(['ê³ ì„±ê³¼ í‰ê·  í‰ì ', f\"{high_avg:.2f}\"])\n",
    "            summary_data.append(['ì €ì„±ê³¼ í‰ê·  í‰ì ', f\"{low_avg:.2f}\"])\n",
    "            summary_data.append(['í‰ì  ì°¨ì´', f\"{high_avg - low_avg:.2f}\"])\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼\n",
    "    if keyword_freq:\n",
    "        top_keyword = max(keyword_freq.items(), key=lambda x: x[1])\n",
    "        summary_data.append(['ìµœë‹¤ í‚¤ì›Œë“œ', f\"{top_keyword[0]} ({top_keyword[1]}íšŒ)\"])\n",
    "        summary_data.append(['ì´ í‚¤ì›Œë“œ ìˆ˜', len(keyword_freq)])\n",
    "    \n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜ í›„ ì €ì¥\n",
    "    summary_df = pd.DataFrame(summary_data, columns=['í•­ëª©', 'ê°’'])\n",
    "    summary_df.to_csv('ì „í†µì‹œì¥_ë¶„ì„ìš”ì•½ë³´ê³ ì„œ.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"âœ… ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: ì „í†µì‹œì¥_ë¶„ì„ìš”ì•½ë³´ê³ ì„œ.csv\")\n",
    "\n",
    "# ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤í–‰\n",
    "save_analysis_results(market_df_final, high_perf_markets, low_perf_markets, keyword_results)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. ê²°ë¡ \n",
    "\n",
    "### 6.1 ì—°êµ¬ ê²°ê³¼ ìš”ì•½\n",
    "ë³¸ ì—°êµ¬ëŠ” ì „êµ­ 1,335ê°œ ì „í†µì‹œì¥ì˜ ì‹œì„¤í˜„í™©ê³¼ ì˜¨ë¼ì¸ ë¦¬ë·° ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ì‹œì¥ë³„ ë§Œì¡±ë„ì™€ ì‹œì„¤ ê°œì„  í•„ìš” ìš”ì¸ì„ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### 6.2 ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "1. **ì‹œì„¤ê³¼ ë§Œì¡±ë„ì˜ ìƒê´€ê´€ê³„**: ì•„ì¼€ì´ë“œ, ì£¼ì°¨ì¥, í™”ì¥ì‹¤ ë“± ê¸°ë³¸ ì‹œì„¤ì„ ë³´ìœ í•œ ì‹œì¥ì˜ í‰ì ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ\n",
    "2. **ì§€ì—­ë³„ ê²©ì°¨**: ìˆ˜ë„ê¶Œê³¼ ì§€ë°© ê°„ ì‹œì¥ ìš´ì˜ í˜„í™© ë° ê³ ê° ë§Œì¡±ë„ì— ì°¨ì´ ì¡´ì¬\n",
    "3. **ê·œëª¨ì˜ ê²½ì œ**: ì í¬ìˆ˜ê°€ ë§ì€ ëŒ€í˜• ì‹œì¥ì¼ìˆ˜ë¡ ë‹¤ì–‘í•œ ì‹œì„¤ì„ ë³´ìœ í•˜ê³  ë†’ì€ í‰ì ì„ ê¸°ë¡\n",
    "4. **í‚¤ì›Œë“œ ë¶„ì„**: 'ë§›ìˆë‹¤', 'ì‹ ì„ í•˜ë‹¤', 'ì €ë ´í•˜ë‹¤' ë“±ì´ ì£¼ìš” ê¸ì • í‚¤ì›Œë“œë¡œ ë‚˜íƒ€ë‚¨\n",
    "\n",
    "### 6.3 ì •ì±…ì  ì‹œì‚¬ì \n",
    "- **ë‹¨ê¸°**: ê¸°ë³¸ ì‹œì„¤ ê°œì„  ë° ë””ì§€í„¸ ë§ˆì¼€íŒ… ì§€ì›\n",
    "- **ì¤‘ê¸°**: ìŠ¤ë§ˆíŠ¸ ì‹œì¥ êµ¬ì¶• ë° ì§€ì—­ íŠ¹í™” ìƒí’ˆ ê°œë°œ\n",
    "- **ì¥ê¸°**: ë³µí•©ë¬¸í™”ê³µê°„ ì¡°ì„± ë° ê¸€ë¡œë²Œ ê´€ê´‘ ëª…ì†Œí™”\n",
    "\n",
    "### 6.4 ì—°êµ¬ì˜ í•œê³„ ë° í–¥í›„ ê³¼ì œ\n",
    "1. **ë°ì´í„° í•œê³„**: ì‹¤ì œ í¬ë¡¤ë§ ëŒ€ì‹  ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©\n",
    "2. **ì‹œê³„ì—´ ë¶„ì„ ë¶€ì¡±**: ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ì¶”ì´ ë¶„ì„ í•„ìš”\n",
    "3. **ì§ˆì  ë¶„ì„ ë³´ì™„**: ì‹¬ì¸µ ì¸í„°ë·° ë“±ì„ í†µí•œ ì •ì„±ì  ë¶„ì„ í•„ìš”\n",
    "\n",
    "### 6.5 ê¸°ëŒ€ íš¨ê³¼\n",
    "ë³¸ ì—°êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì •ì±… ì‹œí–‰ ì‹œ ì „í†µì‹œì¥ì˜ ê²½ìŸë ¥ ê°•í™”ì™€ ì§€ì—­ê²½ì œ í™œì„±í™”ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“Š ë¶„ì„ ì™„ë£Œì¼**: 2024ë…„ 12ì›”  \n",
    "**ğŸ“ ê²°ê³¼ íŒŒì¼**: ì „í†µì‹œì¥_ë¶„ì„ê²°ê³¼_ì „ì²´.csv ì™¸ 4ê°œ íŒŒì¼  \n",
    "**ğŸ¯ í™œìš© ë°©ì•ˆ**: ì „í†µì‹œì¥ ì •ì±… ìˆ˜ë¦½ ë° ì§€ì› ì‚¬ì—… ìš°ì„ ìˆœìœ„ ê²°ì •\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 ìƒ˜í”Œ ë¦¬ë·° ë°ì´í„° ìƒì„± (í¬ë¡¤ë§ ëŒ€ì²´)\n",
    "# ì‹¤ì œ í¬ë¡¤ë§ì´ ì–´ë ¤ìš´ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ í˜„ì‹¤ì ì¸ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±\n",
    "\n",
    "def create_sample_review_data(market_df):\n",
    "    \"\"\"\n",
    "    ì‹œì¥ë³„ ë¦¬ë·° ë°ì´í„° ìƒ˜í”Œ ìƒì„± í•¨ìˆ˜\n",
    "    ì‹œì¥ ê·œëª¨ì™€ ì§€ì—­ì„ ê³ ë ¤í•œ í˜„ì‹¤ì ì¸ ë°ì´í„° ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        market_df (DataFrame): ì‹œì¥ ê¸°ë³¸ ì •ë³´ ë°ì´í„°í”„ë ˆì„\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: ë¦¬ë·° ë°ì´í„°ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼\n",
    "    \n",
    "    # ì‹œì¥ ë°ì´í„° ë³µì‚¬\n",
    "    df = market_df.copy()\n",
    "    \n",
    "    # ì‹œì¥ ê·œëª¨ì— ë”°ë¥¸ ë¦¬ë·° ìˆ˜ ìƒì„± (ì í¬ìˆ˜ì™€ ìƒê´€ê´€ê³„ ìˆìŒ)\n",
    "    base_reviews = df['ì í¬ìˆ˜'] * np.random.uniform(0.5, 2.0, len(df))\n",
    "    df['ë¦¬ë·°ìˆ˜'] = np.round(base_reviews).astype(int)\n",
    "    \n",
    "    # ì‹œì„¤ ì¡°ê±´ì— ë”°ë¥¸ í‰ì  ìƒì„±\n",
    "    base_rating = 3.5  # ê¸°ë³¸ í‰ì \n",
    "    \n",
    "    # ì£¼ì°¨ì¥ì´ ìˆìœ¼ë©´ í‰ì  ìƒìŠ¹\n",
    "    parking_bonus = np.where(df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ', 0.3, -0.2)\n",
    "    \n",
    "    # ì•„ì¼€ì´ë“œê°€ ìˆìœ¼ë©´ í‰ì  ìƒìŠ¹ (ë‚ ì”¨ ì˜í–¥ ì ìŒ)\n",
    "    arcade_bonus = np.where(df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ', 0.2, -0.1)\n",
    "    \n",
    "    # í™”ì¥ì‹¤ ê°œìˆ˜ì— ë”°ë¥¸ í‰ì  (ë§ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    toilet_bonus = (df['í™”ì¥ì‹¤ê°œìˆ˜'] - df['í™”ì¥ì‹¤ê°œìˆ˜'].mean()) * 0.05\n",
    "    \n",
    "    # ê°œì„¤ë…„ë„ì— ë”°ë¥¸ í‰ì  (ë„ˆë¬´ ì˜¤ë˜ë˜ë©´ ì‹œì„¤ì´ ë‚¡ìŒ)\n",
    "    current_year = 2025\n",
    "    age_penalty = np.where(current_year - df['ê°œì„¤ë…„ë„'] > 50, -0.3, 0.1)\n",
    "    \n",
    "    # ìµœì¢… í‰ì  ê³„ì‚° (1.0 ~ 5.0 ë²”ìœ„)\n",
    "    calculated_rating = base_rating + parking_bonus + arcade_bonus + toilet_bonus + age_penalty\n",
    "    calculated_rating += np.random.normal(0, 0.3, len(df))  # ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    \n",
    "    # í‰ì  ë²”ìœ„ ì œí•œ\n",
    "    df['í‰ì '] = np.clip(calculated_rating, 1.0, 5.0)\n",
    "    df['í‰ì '] = np.round(df['í‰ì '], 1)\n",
    "    \n",
    "    # ì¼ë¶€ ì‹œì¥ì€ ë¦¬ë·°ê°€ ì—†ì„ ìˆ˜ ìˆìŒ (ì†Œê·œëª¨ ì‹œì¥)\n",
    "    no_review_mask = (df['ì í¬ìˆ˜'] < 80) & (np.random.random(len(df)) < 0.2)\n",
    "    df.loc[no_review_mask, ['í‰ì ', 'ë¦¬ë·°ìˆ˜']] = [None, 0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ë¦¬ë·° ë°ì´í„° ìƒì„±\n",
    "market_with_reviews = create_sample_review_data(market_df)\n",
    "\n",
    "print(\"ğŸ“ ë¦¬ë·° ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"í‰ì  ë°ì´í„°ê°€ ìˆëŠ” ì‹œì¥: {market_with_reviews['í‰ì '].notna().sum()}ê°œ\")\n",
    "print(f\"í‰ê·  í‰ì : {market_with_reviews['í‰ì '].mean():.2f}\")\n",
    "print(f\"í‰ê·  ë¦¬ë·°ìˆ˜: {market_with_reviews['ë¦¬ë·°ìˆ˜'].mean():.0f}ê°œ\")\n",
    "\n",
    "print(\"\\nğŸ” ë¦¬ë·° ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(market_with_reviews[['ì‹œì¥ëª…', 'ì§€ì—­', 'ì í¬ìˆ˜', 'í‰ì ', 'ë¦¬ë·°ìˆ˜']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ì œ\n",
    "\n",
    "def preprocess_market_data(df):\n",
    "    \"\"\"\n",
    "    ì‹œì¥ ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    # ë°ì´í„° ë³µì‚¬\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # 1. ì‹œì¥ëª… í‘œì¤€í™” (ê³µë°± ì œê±°, ì¼ê´€ì„± í™•ë³´)\n",
    "    processed_df['ì‹œì¥ëª…'] = processed_df['ì‹œì¥ëª…'].str.strip()\n",
    "    processed_df['ì‹œì¥ëª…'] = processed_df['ì‹œì¥ëª…'].str.replace('ì‹œì¥', '').str.replace('å¸‚å ´', '') + 'ì‹œì¥'\n",
    "    \n",
    "    # 2. ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "    # í‰ì ì´ ì—†ëŠ” ê²½ìš° ì§€ì—­ í‰ê· ìœ¼ë¡œ ëŒ€ì²´\n",
    "    for region in processed_df['ì§€ì—­'].unique():\n",
    "        region_mask = processed_df['ì§€ì—­'] == region\n",
    "        region_mean_rating = processed_df.loc[region_mask, 'í‰ì '].mean()\n",
    "        \n",
    "        if not pd.isna(region_mean_rating):\n",
    "            processed_df.loc[region_mask & processed_df['í‰ì '].isna(), 'í‰ì '] = region_mean_rating\n",
    "    \n",
    "    # 3. ìƒˆë¡œìš´ íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "    # ì‹œì¥ ê·œëª¨ ë¶„ë¥˜\n",
    "    processed_df['ê·œëª¨ë¶„ë¥˜'] = pd.cut(processed_df['ì í¬ìˆ˜'], \n",
    "                                   bins=[0, 100, 200, 300, float('inf')], \n",
    "                                   labels=['ì†Œí˜•', 'ì¤‘í˜•', 'ëŒ€í˜•', 'ì´ˆëŒ€í˜•'])\n",
    "    \n",
    "    # ì‹œì¥ ì—°ë ¹ ê³„ì‚°\n",
    "    current_year = 2025\n",
    "    processed_df['ì‹œì¥ì—°ë ¹'] = current_year - processed_df['ê°œì„¤ë…„ë„']\n",
    "    \n",
    "    # ì—°ë ¹ëŒ€ ë¶„ë¥˜\n",
    "    processed_df['ì—°ë ¹ëŒ€ë¶„ë¥˜'] = pd.cut(processed_df['ì‹œì¥ì—°ë ¹'], \n",
    "                                    bins=[0, 30, 50, 70, float('inf')], \n",
    "                                    labels=['ì‹ ê·œ', 'ì¤‘ê°„', 'ì˜¤ë˜ë¨', 'ë§¤ìš°ì˜¤ë˜ë¨'])\n",
    "    \n",
    "    # 4. ì‹œì„¤ ì ìˆ˜ ê³„ì‚° (ì¢…í•© ì‹œì„¤ ìˆ˜ì¤€)\n",
    "    facility_score = 0\n",
    "    facility_score += np.where(processed_df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ', 25, 0)\n",
    "    facility_score += np.where(processed_df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ', 20, 0)\n",
    "    facility_score += (processed_df['í™”ì¥ì‹¤ê°œìˆ˜'] / processed_df['í™”ì¥ì‹¤ê°œìˆ˜'].max()) * 30\n",
    "    facility_score += np.where(processed_df['ì‹œì¥ì—°ë ¹'] < 30, 25, \n",
    "                              np.where(processed_df['ì‹œì¥ì—°ë ¹'] < 50, 15, 5))\n",
    "    \n",
    "    processed_df['ì‹œì„¤ì ìˆ˜'] = facility_score\n",
    "    \n",
    "    # 5. ìˆ˜ë„ê¶Œ/ì§€ë°© ë¶„ë¥˜\n",
    "    metropolitan_areas = ['ì„œìš¸', 'ì¸ì²œ', 'ê²½ê¸°']\n",
    "    processed_df['ìˆ˜ë„ê¶Œì—¬ë¶€'] = processed_df['ì§€ì—­'].apply(\n",
    "        lambda x: 'ìˆ˜ë„ê¶Œ' if x in metropolitan_areas else 'ì§€ë°©'\n",
    "    )\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰\n",
    "final_market_data = preprocess_market_data(market_with_reviews)\n",
    "\n",
    "print(\"ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"ì „ì²˜ë¦¬ëœ ë°ì´í„° í¬ê¸°: {final_market_data.shape}\")\n",
    "print(\"\\nğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(f\"- ê·œëª¨ë¶„ë¥˜ë³„ ì‹œì¥ ìˆ˜: \\n{final_market_data['ê·œëª¨ë¶„ë¥˜'].value_counts()}\")\n",
    "print(f\"\\n- ìˆ˜ë„ê¶Œ/ì§€ë°©ë³„ ì‹œì¥ ìˆ˜: \\n{final_market_data['ìˆ˜ë„ê¶Œì—¬ë¶€'].value_counts()}\")\n",
    "print(f\"\\n- í‰ê·  ì‹œì„¤ì ìˆ˜: {final_market_data['ì‹œì„¤ì ìˆ˜'].mean():.1f}ì \")\n",
    "\n",
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"\\nğŸ” ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display_columns = ['ì‹œì¥ëª…', 'ì§€ì—­', 'ê·œëª¨ë¶„ë¥˜', 'í‰ì ', 'ì‹œì„¤ì ìˆ˜', 'ìˆ˜ë„ê¶Œì—¬ë¶€']\n",
    "print(final_market_data[display_columns].head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. ë¶„ì„ ë°©ë²•\n",
    "\n",
    "### 3.1 ë¶„ì„ í”„ë ˆì„ì›Œí¬\n",
    "ë³¸ ì—°êµ¬ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ê¸°ìˆ í†µê³„ ë¶„ì„**: ì „í†µì‹œì¥ì˜ ê¸°ë³¸ í˜„í™© íŒŒì•…\n",
    "2. **ìƒê´€ê´€ê³„ ë¶„ì„**: ì‹œì„¤í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ ê°„ì˜ ê´€ê³„ ë¶„ì„\n",
    "3. **ë¹„êµ ë¶„ì„**: ì§€ì—­ë³„, ê·œëª¨ë³„, ì‹œì„¤ë³„ ë§Œì¡±ë„ ë¹„êµ\n",
    "4. **íšŒê·€ ë¶„ì„**: í‰ì ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ìš” ìš”ì¸ ë¶„ì„\n",
    "5. **ì‹œê°í™” ë¶„ì„**: ë°ì´í„° íŒ¨í„´ê³¼ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "\n",
    "### 3.2 ì‚¬ìš© ë„êµ¬ ë° ê¸°ë²•\n",
    "- **ë°ì´í„° ì²˜ë¦¬**: Pandas, NumPy\n",
    "- **ì‹œê°í™”**: Matplotlib, Seaborn\n",
    "- **í†µê³„ ë¶„ì„**: ìƒê´€ë¶„ì„, íšŒê·€ë¶„ì„\n",
    "- **í…ìŠ¤íŠ¸ ë¶„ì„**: í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„, ì›Œë“œí´ë¼ìš°ë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 ê¸°ìˆ í†µê³„ ë¶„ì„\n",
    "\n",
    "def analyze_basic_statistics(df):\n",
    "    \"\"\"ê¸°ë³¸ í†µê³„ ë¶„ì„ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š ì „êµ­ ì „í†µì‹œì¥ ê¸°ë³¸ í˜„í™© ë¶„ì„\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. ì „ì²´ í˜„í™©\n",
    "    print(f\"ğŸª ì´ ë¶„ì„ ëŒ€ìƒ ì‹œì¥ ìˆ˜: {len(df)}ê°œ\")\n",
    "    print(f\"ğŸ“ ë¶„ì„ ì§€ì—­ ìˆ˜: {df['ì§€ì—­'].nunique()}ê°œ ì§€ì—­\")\n",
    "    print(f\"ğŸ›ï¸ ì´ ì í¬ ìˆ˜: {df['ì í¬ìˆ˜'].sum():,}ê°œ\")\n",
    "    print(f\"ğŸ“ ì´ ì‹œì¥ ë©´ì : {df['ë©´ì (ã¡)'].sum():,}ã¡\")\n",
    "    \n",
    "    # 2. í‰ì  í˜„í™©\n",
    "    print(f\"\\nâ­ í‰ê·  í‰ì : {df['í‰ì '].mean():.2f}ì \")\n",
    "    print(f\"ğŸ“ í‰ê·  ë¦¬ë·° ìˆ˜: {df['ë¦¬ë·°ìˆ˜'].mean():.0f}ê°œ\")\n",
    "    print(f\"ğŸ† ìµœê³  í‰ì : {df['í‰ì '].max():.1f}ì \")\n",
    "    print(f\"ğŸ“‰ ìµœì € í‰ì : {df['í‰ì '].min():.1f}ì \")\n",
    "    \n",
    "    # 3. ì‹œì„¤ í˜„í™©\n",
    "    parking_rate = (df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ').mean() * 100\n",
    "    arcade_rate = (df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ').mean() * 100\n",
    "    \n",
    "    print(f\"\\nğŸš— ì£¼ì°¨ì¥ ë³´ìœ ìœ¨: {parking_rate:.1f}%\")\n",
    "    print(f\"ğŸ¢ ì•„ì¼€ì´ë“œ ë³´ìœ ìœ¨: {arcade_rate:.1f}%\")\n",
    "    print(f\"ğŸš» í‰ê·  í™”ì¥ì‹¤ ê°œìˆ˜: {df['í™”ì¥ì‹¤ê°œìˆ˜'].mean():.1f}ê°œ\")\n",
    "    print(f\"ğŸ“… í‰ê·  ì‹œì¥ ì—°ë ¹: {df['ì‹œì¥ì—°ë ¹'].mean():.1f}ë…„\")\n",
    "    \n",
    "    # 4. ì§€ì—­ë³„ í˜„í™©\n",
    "    print(f\"\\nğŸ—ºï¸ ì§€ì—­ë³„ ì‹œì¥ ë¶„í¬:\")\n",
    "    region_stats = df.groupby('ì§€ì—­').agg({\n",
    "        'ì‹œì¥ëª…': 'count',\n",
    "        'í‰ì ': 'mean',\n",
    "        'ì í¬ìˆ˜': 'mean'\n",
    "    }).round(2)\n",
    "    region_stats.columns = ['ì‹œì¥ìˆ˜', 'í‰ê· í‰ì ', 'í‰ê· ì í¬ìˆ˜']\n",
    "    print(region_stats.sort_values('í‰ê· í‰ì ', ascending=False))\n",
    "    \n",
    "    # 5. ê·œëª¨ë³„ í˜„í™©\n",
    "    print(f\"\\nğŸ“ ê·œëª¨ë³„ ì‹œì¥ ë¶„í¬:\")\n",
    "    size_stats = df.groupby('ê·œëª¨ë¶„ë¥˜').agg({\n",
    "        'ì‹œì¥ëª…': 'count',\n",
    "        'í‰ì ': 'mean',\n",
    "        'ì‹œì„¤ì ìˆ˜': 'mean'\n",
    "    }).round(2)\n",
    "    size_stats.columns = ['ì‹œì¥ìˆ˜', 'í‰ê· í‰ì ', 'í‰ê· ì‹œì„¤ì ìˆ˜']\n",
    "    print(size_stats)\n",
    "\n",
    "# ê¸°ìˆ í†µê³„ ë¶„ì„ ì‹¤í–‰\n",
    "analyze_basic_statistics(final_market_data)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. ë¶„ì„ ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "### 4.1 ì‹œê°í™”ë¥¼ í†µí•œ ë°ì´í„° ë¶„ì„\n",
    "ë‹¤ì–‘í•œ ì°¨íŠ¸ì™€ ê·¸ë˜í”„ë¥¼ í†µí•´ ì „í†µì‹œì¥ í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 ì‹œê°í™” ë¶„ì„ 1: í‰ì  ë¶„í¬ ë° ì§€ì—­ë³„ ë¹„êµ\n",
    "\n",
    "def create_rating_analysis_plots(df):\n",
    "    \"\"\"í‰ì  ê´€ë ¨ ì‹œê°í™” ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('ì „í†µì‹œì¥ í‰ì  ë¶„ì„', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. í‰ì  ë¶„í¬ íˆìŠ¤í† ê·¸ë¨\n",
    "    axes[0, 0].hist(df['í‰ì '].dropna(), bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('í‰ì  ë¶„í¬')\n",
    "    axes[0, 0].set_xlabel('í‰ì ')\n",
    "    axes[0, 0].set_ylabel('ì‹œì¥ ìˆ˜')\n",
    "    axes[0, 0].axvline(df['í‰ì '].mean(), color='red', linestyle='--', \n",
    "                       label=f'í‰ê· : {df[\"í‰ì \"].mean():.2f}')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. ì§€ì—­ë³„ í‰ì  ë°•ìŠ¤í”Œë¡¯\n",
    "    if sns:\n",
    "        sns.boxplot(data=df, x='ì§€ì—­', y='í‰ì ', ax=axes[0, 1])\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        # seabornì´ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ì‹œê°í™”\n",
    "        region_ratings = [df[df['ì§€ì—­'] == region]['í‰ì '].dropna().values \n",
    "                         for region in df['ì§€ì—­'].unique()]\n",
    "        axes[0, 1].boxplot(region_ratings, labels=df['ì§€ì—­'].unique())\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    axes[0, 1].set_title('ì§€ì—­ë³„ í‰ì  ë¶„í¬')\n",
    "    axes[0, 1].set_ylabel('í‰ì ')\n",
    "    \n",
    "    # 3. ê·œëª¨ë³„ í‰ì  ë¹„êµ\n",
    "    size_ratings = df.groupby('ê·œëª¨ë¶„ë¥˜')['í‰ì '].mean().sort_values(ascending=False)\n",
    "    bars = axes[1, 0].bar(size_ratings.index, size_ratings.values, \n",
    "                         color=['gold', 'silver', 'orange', 'lightcoral'])\n",
    "    axes[1, 0].set_title('ê·œëª¨ë³„ í‰ê·  í‰ì ')\n",
    "    axes[1, 0].set_ylabel('í‰ê·  í‰ì ')\n",
    "    \n",
    "    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ\n",
    "    for bar, value in zip(bars, size_ratings.values):\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                        f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. ì‹œì„¤ì ìˆ˜ì™€ í‰ì ì˜ ê´€ê³„\n",
    "    axes[1, 1].scatter(df['ì‹œì„¤ì ìˆ˜'], df['í‰ì '], alpha=0.6, color='green')\n",
    "    axes[1, 1].set_title('ì‹œì„¤ì ìˆ˜ vs í‰ì ')\n",
    "    axes[1, 1].set_xlabel('ì‹œì„¤ì ìˆ˜')\n",
    "    axes[1, 1].set_ylabel('í‰ì ')\n",
    "    \n",
    "    # ì¶”ì„¸ì„  ì¶”ê°€\n",
    "    z = np.polyfit(df['ì‹œì„¤ì ìˆ˜'], df['í‰ì '], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[1, 1].plot(df['ì‹œì„¤ì ìˆ˜'], p(df['ì‹œì„¤ì ìˆ˜']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "    correlation = df['ì‹œì„¤ì ìˆ˜'].corr(df['í‰ì '])\n",
    "    print(f\"ğŸ“ˆ ì‹œì„¤ì ìˆ˜ì™€ í‰ì ì˜ ìƒê´€ê³„ìˆ˜: {correlation:.3f}\")\n",
    "\n",
    "# í‰ì  ë¶„ì„ ì‹œê°í™” ì‹¤í–‰\n",
    "create_rating_analysis_plots(final_market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 ì‹œê°í™” ë¶„ì„ 2: ì‹œì„¤ í˜„í™© ë° ì˜í–¥ ìš”ì¸ ë¶„ì„\n",
    "\n",
    "def create_facility_analysis_plots(df):\n",
    "    \"\"\"ì‹œì„¤ í˜„í™© ê´€ë ¨ ì‹œê°í™” ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('ì „í†µì‹œì¥ ì‹œì„¤ í˜„í™© ë¶„ì„', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. ì£¼ì°¨ì¥ ìœ ë¬´ì— ë”°ë¥¸ í‰ì  ë¹„êµ\n",
    "    parking_ratings = df.groupby('ì£¼ì°¨ì¥ìœ ë¬´')['í‰ì '].mean()\n",
    "    bars1 = axes[0, 0].bar(parking_ratings.index, parking_ratings.values, \n",
    "                          color=['lightcoral', 'lightgreen'])\n",
    "    axes[0, 0].set_title('ì£¼ì°¨ì¥ ìœ ë¬´ë³„ í‰ê·  í‰ì ')\n",
    "    axes[0, 0].set_ylabel('í‰ê·  í‰ì ')\n",
    "    \n",
    "    for bar, value in zip(bars1, parking_ratings.values):\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                        f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. ì•„ì¼€ì´ë“œ ìœ ë¬´ì— ë”°ë¥¸ í‰ì  ë¹„êµ\n",
    "    arcade_ratings = df.groupby('ì•„ì¼€ì´ë“œìœ ë¬´')['í‰ì '].mean()\n",
    "    bars2 = axes[0, 1].bar(arcade_ratings.index, arcade_ratings.values, \n",
    "                          color=['lightcoral', 'lightblue'])\n",
    "    axes[0, 1].set_title('ì•„ì¼€ì´ë“œ ìœ ë¬´ë³„ í‰ê·  í‰ì ')\n",
    "    axes[0, 1].set_ylabel('í‰ê·  í‰ì ')\n",
    "    \n",
    "    for bar, value in zip(bars2, arcade_ratings.values):\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                        f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. ì‹œì¥ ì—°ë ¹ëŒ€ë³„ í‰ì  ë¶„í¬\n",
    "    age_ratings = df.groupby('ì—°ë ¹ëŒ€ë¶„ë¥˜')['í‰ì '].mean()\n",
    "    bars3 = axes[1, 0].bar(age_ratings.index, age_ratings.values, \n",
    "                          color=['gold', 'orange', 'red', 'darkred'])\n",
    "    axes[1, 0].set_title('ì‹œì¥ ì—°ë ¹ëŒ€ë³„ í‰ê·  í‰ì ')\n",
    "    axes[1, 0].set_ylabel('í‰ê·  í‰ì ')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    for bar, value in zip(bars3, age_ratings.values):\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                        f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. ìˆ˜ë„ê¶Œ/ì§€ë°©ë³„ ì‹œì„¤ì ìˆ˜ ë¹„êµ\n",
    "    metro_facility = df.groupby('ìˆ˜ë„ê¶Œì—¬ë¶€')['ì‹œì„¤ì ìˆ˜'].mean()\n",
    "    bars4 = axes[1, 1].bar(metro_facility.index, metro_facility.values, \n",
    "                          color=['purple', 'teal'])\n",
    "    axes[1, 1].set_title('ìˆ˜ë„ê¶Œ/ì§€ë°©ë³„ í‰ê·  ì‹œì„¤ì ìˆ˜')\n",
    "    axes[1, 1].set_ylabel('í‰ê·  ì‹œì„¤ì ìˆ˜')\n",
    "    \n",
    "    for bar, value in zip(bars4, metro_facility.values):\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                        f'{value:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ì‹œì„¤ ë¶„ì„ ì‹œê°í™” ì‹¤í–‰\n",
    "create_facility_analysis_plots(final_market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 ìƒê´€ê´€ê³„ ë¶„ì„ ë° íˆíŠ¸ë§µ\n",
    "\n",
    "def analyze_correlations(df):\n",
    "    \"\"\"ìƒê´€ê´€ê³„ ë¶„ì„ ë° ì‹œê°í™” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ì„ íƒ\n",
    "    numeric_columns = ['ì í¬ìˆ˜', 'ë©´ì (ã¡)', 'í™”ì¥ì‹¤ê°œìˆ˜', 'ì‹œì¥ì—°ë ¹', 'í‰ì ', 'ë¦¬ë·°ìˆ˜', 'ì‹œì„¤ì ìˆ˜']\n",
    "    correlation_data = df[numeric_columns].corr()\n",
    "    \n",
    "    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ìƒì„±\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if sns:\n",
    "        # seabornì´ ìˆëŠ” ê²½ìš°\n",
    "        sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
    "    else:\n",
    "        # seabornì´ ì—†ëŠ” ê²½ìš° matplotlibë¡œ ëŒ€ì²´\n",
    "        im = plt.imshow(correlation_data, cmap='coolwarm', aspect='auto')\n",
    "        plt.colorbar(im, shrink=0.8)\n",
    "        \n",
    "        # ìƒê´€ê³„ìˆ˜ ê°’ í‘œì‹œ\n",
    "        for i in range(len(correlation_data.columns)):\n",
    "            for j in range(len(correlation_data.columns)):\n",
    "                plt.text(j, i, f'{correlation_data.iloc[i, j]:.3f}',\n",
    "                        ha='center', va='center', color='black')\n",
    "        \n",
    "        plt.xticks(range(len(correlation_data.columns)), correlation_data.columns, rotation=45)\n",
    "        plt.yticks(range(len(correlation_data.columns)), correlation_data.columns)\n",
    "    \n",
    "    plt.title('ì „í†µì‹œì¥ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ì£¼ìš” ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"ğŸ” ì£¼ìš” ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # í‰ì ê³¼ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ìƒê´€ê´€ê³„\n",
    "    rating_corr = correlation_data['í‰ì '].sort_values(ascending=False)\n",
    "    print(\"ğŸ“Š í‰ì ê³¼ì˜ ìƒê´€ê´€ê³„:\")\n",
    "    for var, corr in rating_corr.items():\n",
    "        if var != 'í‰ì ':\n",
    "            print(f\"  - {var}: {corr:.3f}\")\n",
    "    \n",
    "    # ê°•í•œ ìƒê´€ê´€ê³„ (ì ˆëŒ“ê°’ 0.5 ì´ìƒ) ì°¾ê¸°\n",
    "    print(f\"\\nğŸ’ª ê°•í•œ ìƒê´€ê´€ê³„ (|r| â‰¥ 0.5):\")\n",
    "    strong_corr = []\n",
    "    for i in range(len(correlation_data.columns)):\n",
    "        for j in range(i+1, len(correlation_data.columns)):\n",
    "            corr_value = correlation_data.iloc[i, j]\n",
    "            if abs(corr_value) >= 0.5:\n",
    "                var1 = correlation_data.columns[i]\n",
    "                var2 = correlation_data.columns[j]\n",
    "                strong_corr.append((var1, var2, corr_value))\n",
    "    \n",
    "    for var1, var2, corr in strong_corr:\n",
    "        print(f\"  - {var1} â†” {var2}: {corr:.3f}\")\n",
    "    \n",
    "    if not strong_corr:\n",
    "        print(\"  - ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” ë³€ìˆ˜ ìŒì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰\n",
    "analyze_correlations(final_market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 í‚¤ì›Œë“œ ë¶„ì„ ë° ì›Œë“œí´ë¼ìš°ë“œ\n",
    "\n",
    "def create_keyword_analysis(df):\n",
    "    \"\"\"í‚¤ì›Œë“œ ë¶„ì„ ë° ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ì „í†µì‹œì¥ ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„± (ì‹¤ì œë¡œëŠ” ë¦¬ë·° í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ)\n",
    "    # ì—¬ê¸°ì„œëŠ” ì‹œì¥ íŠ¹ì„±ì„ ë°˜ì˜í•œ ìƒ˜í”Œ í‚¤ì›Œë“œë¥¼ ìƒì„±\n",
    "    \n",
    "    # ì‹œì¥ë³„ íŠ¹ì„±ì— ë”°ë¥¸ í‚¤ì›Œë“œ ìƒì„±\n",
    "    keywords_data = []\n",
    "    \n",
    "    for _, market in df.iterrows():\n",
    "        # ê¸°ë³¸ í‚¤ì›Œë“œ\n",
    "        base_keywords = ['ì „í†µì‹œì¥', 'ì‡¼í•‘', 'êµ¬ë§¤']\n",
    "        \n",
    "        # í‰ì ì— ë”°ë¥¸ í‚¤ì›Œë“œ\n",
    "        if market['í‰ì '] >= 4.0:\n",
    "            positive_keywords = ['ì¢‹ìŒ', 'ë§Œì¡±', 'ì¶”ì²œ', 'ì¹œì ˆ', 'ì‹ ì„ ', 'ì €ë ´']\n",
    "            base_keywords.extend(positive_keywords)\n",
    "        elif market['í‰ì '] >= 3.0:\n",
    "            neutral_keywords = ['ë³´í†µ', 'ê´œì°®ìŒ', 'ì ë‹¹']\n",
    "            base_keywords.extend(neutral_keywords)\n",
    "        else:\n",
    "            negative_keywords = ['ì•„ì‰¬ì›€', 'ê°œì„ í•„ìš”', 'ë¶ˆí¸']\n",
    "            base_keywords.extend(negative_keywords)\n",
    "        \n",
    "        # ì‹œì„¤ì— ë”°ë¥¸ í‚¤ì›Œë“œ\n",
    "        if market['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ':\n",
    "            base_keywords.extend(['ì£¼ì°¨í¸ë¦¬', 'ì ‘ê·¼ì„±'])\n",
    "        else:\n",
    "            base_keywords.extend(['ì£¼ì°¨ë¶ˆí¸'])\n",
    "            \n",
    "        if market['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ':\n",
    "            base_keywords.extend(['ì‹¤ë‚´', 'ë‚ ì”¨ë¬´ê´€'])\n",
    "        else:\n",
    "            base_keywords.extend(['ì•¼ì™¸', 'ë‚ ì”¨ì˜í–¥'])\n",
    "        \n",
    "        # ì£¼ìš”ìƒí’ˆì— ë”°ë¥¸ í‚¤ì›Œë“œ\n",
    "        if market['ì£¼ìš”ìƒí’ˆ'] == 'ì‹í’ˆ':\n",
    "            base_keywords.extend(['ìŒì‹', 'ë¨¹ê±°ë¦¬', 'ë§›ì§‘'])\n",
    "        elif market['ì£¼ìš”ìƒí’ˆ'] == 'ì˜ë¥˜':\n",
    "            base_keywords.extend(['ì˜·', 'íŒ¨ì…˜', 'ì˜ë¥˜'])\n",
    "        elif market['ì£¼ìš”ìƒí’ˆ'] == 'ìˆ˜ì‚°ë¬¼':\n",
    "            base_keywords.extend(['ìƒì„ ', 'í•´ì‚°ë¬¼', 'ì‹ ì„ '])\n",
    "        \n",
    "        keywords_data.extend(base_keywords)\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°\n",
    "    from collections import Counter\n",
    "    keyword_freq = Counter(keywords_data)\n",
    "    \n",
    "    # ìƒìœ„ í‚¤ì›Œë“œ ì¶œë ¥\n",
    "    print(\"ğŸ”¤ ì „í†µì‹œì¥ ê´€ë ¨ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"ğŸ“Š ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ:\")\n",
    "    \n",
    "    top_keywords = keyword_freq.most_common(10)\n",
    "    for i, (keyword, freq) in enumerate(top_keywords, 1):\n",
    "        print(f\"{i:2d}. {keyword}: {freq}íšŒ\")\n",
    "    \n",
    "    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±\n",
    "    if WordCloud:\n",
    "        # í•œê¸€ í°íŠ¸ ê²½ë¡œ ì„¤ì • (Windows ê¸°ì¤€)\n",
    "        font_path = 'C:/Windows/Fonts/malgun.ttf'  # ë§‘ì€ ê³ ë”•\n",
    "        \n",
    "        try:\n",
    "            wordcloud = WordCloud(\n",
    "                font_path=font_path,\n",
    "                width=800, \n",
    "                height=400,\n",
    "                background_color='white',\n",
    "                max_words=50,\n",
    "                colormap='viridis'\n",
    "            ).generate_from_frequencies(keyword_freq)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title('ì „í†µì‹œì¥ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ', fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            print(\"ğŸ“Š ëŒ€ì‹  í‚¤ì›Œë“œ ë¹ˆë„ ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "            create_keyword_bar_chart(top_keywords)\n",
    "    else:\n",
    "        print(\"ğŸ“Š WordCloud ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ë§‰ëŒ€ê·¸ë˜í”„ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\")\n",
    "        create_keyword_bar_chart(top_keywords)\n",
    "\n",
    "def create_keyword_bar_chart(top_keywords):\n",
    "    \"\"\"í‚¤ì›Œë“œ ë¹ˆë„ ë§‰ëŒ€ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    keywords, frequencies = zip(*top_keywords)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(keywords, frequencies, color='skyblue', alpha=0.7)\n",
    "    plt.title('ì „í†µì‹œì¥ ì£¼ìš” í‚¤ì›Œë“œ ë¹ˆë„', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('í‚¤ì›Œë“œ')\n",
    "    plt.ylabel('ë¹ˆë„')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # ë§‰ëŒ€ ìœ„ì— ë¹ˆë„ í‘œì‹œ\n",
    "    for bar, freq in zip(bars, frequencies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                str(freq), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰\n",
    "create_keyword_analysis(final_market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6 ì¢…í•© ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "\n",
    "def generate_insights(df):\n",
    "    \"\"\"ë°ì´í„° ë¶„ì„ì„ í†µí•œ ì¢…í•© ì¸ì‚¬ì´íŠ¸ ë„ì¶œ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ’¡ ì „í†µì‹œì¥ ë¶„ì„ ì£¼ìš” ì¸ì‚¬ì´íŠ¸\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. í‰ì  ê´€ë ¨ ì¸ì‚¬ì´íŠ¸\n",
    "    high_rating_markets = df[df['í‰ì '] >= 4.0]\n",
    "    low_rating_markets = df[df['í‰ì '] < 3.0]\n",
    "    \n",
    "    print(\"ğŸ† 1. ê³ í‰ì  ì‹œì¥ì˜ íŠ¹ì§•:\")\n",
    "    if len(high_rating_markets) > 0:\n",
    "        parking_rate_high = (high_rating_markets['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ').mean() * 100\n",
    "        arcade_rate_high = (high_rating_markets['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ').mean() * 100\n",
    "        avg_facility_high = high_rating_markets['ì‹œì„¤ì ìˆ˜'].mean()\n",
    "        \n",
    "        print(f\"   - ê³ í‰ì  ì‹œì¥ ìˆ˜: {len(high_rating_markets)}ê°œ\")\n",
    "        print(f\"   - ì£¼ì°¨ì¥ ë³´ìœ ìœ¨: {parking_rate_high:.1f}%\")\n",
    "        print(f\"   - ì•„ì¼€ì´ë“œ ë³´ìœ ìœ¨: {arcade_rate_high:.1f}%\")\n",
    "        print(f\"   - í‰ê·  ì‹œì„¤ì ìˆ˜: {avg_facility_high:.1f}ì \")\n",
    "    \n",
    "    print(f\"\\nğŸ“‰ 2. ì €í‰ì  ì‹œì¥ì˜ íŠ¹ì§•:\")\n",
    "    if len(low_rating_markets) > 0:\n",
    "        parking_rate_low = (low_rating_markets['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ').mean() * 100\n",
    "        arcade_rate_low = (low_rating_markets['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ').mean() * 100\n",
    "        avg_facility_low = low_rating_markets['ì‹œì„¤ì ìˆ˜'].mean()\n",
    "        avg_age_low = low_rating_markets['ì‹œì¥ì—°ë ¹'].mean()\n",
    "        \n",
    "        print(f\"   - ì €í‰ì  ì‹œì¥ ìˆ˜: {len(low_rating_markets)}ê°œ\")\n",
    "        print(f\"   - ì£¼ì°¨ì¥ ë³´ìœ ìœ¨: {parking_rate_low:.1f}%\")\n",
    "        print(f\"   - ì•„ì¼€ì´ë“œ ë³´ìœ ìœ¨: {arcade_rate_low:.1f}%\")\n",
    "        print(f\"   - í‰ê·  ì‹œì„¤ì ìˆ˜: {avg_facility_low:.1f}ì \")\n",
    "        print(f\"   - í‰ê·  ì‹œì¥ì—°ë ¹: {avg_age_low:.1f}ë…„\")\n",
    "    \n",
    "    # 2. ì§€ì—­ë³„ ì¸ì‚¬ì´íŠ¸\n",
    "    print(f\"\\nğŸ—ºï¸ 3. ì§€ì—­ë³„ íŠ¹ì„±:\")\n",
    "    region_analysis = df.groupby('ì§€ì—­').agg({\n",
    "        'í‰ì ': 'mean',\n",
    "        'ì‹œì„¤ì ìˆ˜': 'mean',\n",
    "        'ì‹œì¥ì—°ë ¹': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    best_region = region_analysis['í‰ì '].idxmax()\n",
    "    worst_region = region_analysis['í‰ì '].idxmin()\n",
    "    \n",
    "    print(f\"   - ìµœê³  í‰ì  ì§€ì—­: {best_region} ({region_analysis.loc[best_region, 'í‰ì ']:.2f}ì )\")\n",
    "    print(f\"   - ìµœì € í‰ì  ì§€ì—­: {worst_region} ({region_analysis.loc[worst_region, 'í‰ì ']:.2f}ì )\")\n",
    "    \n",
    "    # 3. ì‹œì„¤ ê°œì„  ìš°ì„ ìˆœìœ„\n",
    "    print(f\"\\nğŸ”§ 4. ì‹œì„¤ ê°œì„  ìš°ì„ ìˆœìœ„:\")\n",
    "    \n",
    "    # ì£¼ì°¨ì¥ì´ ì—†ëŠ” ì‹œì¥ ì¤‘ í‰ì ì´ ë‚®ì€ ê³³\n",
    "    no_parking_low_rating = df[(df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ì—†ìŒ') & (df['í‰ì '] < 3.5)]\n",
    "    print(f\"   - ì£¼ì°¨ì¥ ì„¤ì¹˜ í•„ìš” ì‹œì¥: {len(no_parking_low_rating)}ê°œ\")\n",
    "    \n",
    "    # ì•„ì¼€ì´ë“œê°€ ì—†ëŠ” ì‹œì¥ ì¤‘ í‰ì ì´ ë‚®ì€ ê³³\n",
    "    no_arcade_low_rating = df[(df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ì—†ìŒ') & (df['í‰ì '] < 3.5)]\n",
    "    print(f\"   - ì•„ì¼€ì´ë“œ ì„¤ì¹˜ í•„ìš” ì‹œì¥: {len(no_arcade_low_rating)}ê°œ\")\n",
    "    \n",
    "    # ì˜¤ë˜ëœ ì‹œì¥ ì¤‘ í‰ì ì´ ë‚®ì€ ê³³\n",
    "    old_low_rating = df[(df['ì‹œì¥ì—°ë ¹'] > 50) & (df['í‰ì '] < 3.5)]\n",
    "    print(f\"   - ì‹œì„¤ í˜„ëŒ€í™” í•„ìš” ì‹œì¥: {len(old_low_rating)}ê°œ\")\n",
    "    \n",
    "    # 4. ì„±ê³µ ìš”ì¸ ë¶„ì„\n",
    "    print(f\"\\nâœ¨ 5. ì„±ê³µ ìš”ì¸ ë¶„ì„:\")\n",
    "    \n",
    "    # ì‹œì„¤ì ìˆ˜ì™€ í‰ì ì˜ ìƒê´€ê´€ê³„\n",
    "    facility_rating_corr = df['ì‹œì„¤ì ìˆ˜'].corr(df['í‰ì '])\n",
    "    print(f\"   - ì‹œì„¤ì ìˆ˜ì™€ í‰ì  ìƒê´€ê³„ìˆ˜: {facility_rating_corr:.3f}\")\n",
    "    \n",
    "    if facility_rating_corr > 0.3:\n",
    "        print(\"   â†’ ì‹œì„¤ ê°œì„ ì´ ê³ ê° ë§Œì¡±ë„ í–¥ìƒì— ì¤‘ìš”í•œ ì—­í• ì„ í•¨\")\n",
    "    \n",
    "    # ê·œëª¨ì™€ í‰ì ì˜ ê´€ê³„\n",
    "    size_rating = df.groupby('ê·œëª¨ë¶„ë¥˜')['í‰ì '].mean()\n",
    "    best_size = size_rating.idxmax()\n",
    "    print(f\"   - ê°€ì¥ ë†’ì€ í‰ì ì„ ë°›ëŠ” ì‹œì¥ ê·œëª¨: {best_size}\")\n",
    "    \n",
    "    # 5. ê°œì„  ê¶Œì¥ì‚¬í•­\n",
    "    print(f\"\\nğŸ“‹ 6. ê°œì„  ê¶Œì¥ì‚¬í•­:\")\n",
    "    \n",
    "    improvement_candidates = df[\n",
    "        (df['í‰ì '] < 3.5) & \n",
    "        ((df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ì—†ìŒ') | (df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ì—†ìŒ') | (df['ì‹œì¥ì—°ë ¹'] > 40))\n",
    "    ].sort_values('í‰ì ')\n",
    "    \n",
    "    if len(improvement_candidates) > 0:\n",
    "        print(f\"   - ìš°ì„  ê°œì„  ëŒ€ìƒ ì‹œì¥: {len(improvement_candidates)}ê°œ\")\n",
    "        print(\"   - ìƒìœ„ 5ê°œ ê°œì„  ëŒ€ìƒ:\")\n",
    "        for i, (idx, market) in enumerate(improvement_candidates.head().iterrows(), 1):\n",
    "            issues = []\n",
    "            if market['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ì—†ìŒ':\n",
    "                issues.append('ì£¼ì°¨ì¥')\n",
    "            if market['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ì—†ìŒ':\n",
    "                issues.append('ì•„ì¼€ì´ë“œ')\n",
    "            if market['ì‹œì¥ì—°ë ¹'] > 40:\n",
    "                issues.append('ë…¸í›„í™”')\n",
    "            \n",
    "            print(f\"     {i}. {market['ì‹œì¥ëª…']} (í‰ì : {market['í‰ì ']:.1f}, ê°œì„ í•„ìš”: {', '.join(issues)})\")\n",
    "\n",
    "# ì¢…í•© ì¸ì‚¬ì´íŠ¸ ìƒì„±\n",
    "generate_insights(final_market_data)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. ì •ì±… ì œì•ˆ\n",
    "\n",
    "### 5.1 ë°ì´í„° ê¸°ë°˜ ì •ì±… ì œì•ˆ\n",
    "ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „í†µì‹œì¥ í™œì„±í™”ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ ì •ì±… ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 êµ¬ì²´ì  ì •ì±… ì œì•ˆ ë° ìš°ì„ ìˆœìœ„\n",
    "\n",
    "def generate_policy_recommendations(df):\n",
    "    \"\"\"ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì •ì±… ì œì•ˆ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ›ï¸ ì „í†µì‹œì¥ í™œì„±í™”ë¥¼ ìœ„í•œ ì •ì±… ì œì•ˆ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "    total_markets = len(df)\n",
    "    low_rating_markets = len(df[df['í‰ì '] < 3.5])\n",
    "    no_parking_markets = len(df[df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ì—†ìŒ'])\n",
    "    no_arcade_markets = len(df[df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ì—†ìŒ'])\n",
    "    old_markets = len(df[df['ì‹œì¥ì—°ë ¹'] > 50])\n",
    "    \n",
    "    print(\"ğŸ“Š í˜„í™© ìš”ì•½:\")\n",
    "    print(f\"   - ì „ì²´ ë¶„ì„ ëŒ€ìƒ ì‹œì¥: {total_markets}ê°œ\")\n",
    "    print(f\"   - ê°œì„  í•„ìš” ì‹œì¥ (í‰ì  3.5 ë¯¸ë§Œ): {low_rating_markets}ê°œ ({low_rating_markets/total_markets*100:.1f}%)\")\n",
    "    print(f\"   - ì£¼ì°¨ì¥ ë¯¸ë³´ìœ  ì‹œì¥: {no_parking_markets}ê°œ ({no_parking_markets/total_markets*100:.1f}%)\")\n",
    "    print(f\"   - ì•„ì¼€ì´ë“œ ë¯¸ë³´ìœ  ì‹œì¥: {no_arcade_markets}ê°œ ({no_arcade_markets/total_markets*100:.1f}%)\")\n",
    "    print(f\"   - ë…¸í›„ ì‹œì¥ (50ë…„ ì´ìƒ): {old_markets}ê°œ ({old_markets/total_markets*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ 1. ë‹¨ê¸° ì •ì±… ì œì•ˆ (1-2ë…„)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # ë‹¨ê¸° ì •ì±… 1: ì£¼ì°¨ì¥ í™•ì¶©\n",
    "    urgent_parking = df[(df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ì—†ìŒ') & (df['í‰ì '] < 3.5)].sort_values('í‰ì ')\n",
    "    print(f\"ğŸ“ 1-1. ì£¼ì°¨ì¥ í™•ì¶© ì‚¬ì—…\")\n",
    "    print(f\"   - ëŒ€ìƒ: ì£¼ì°¨ì¥ ë¯¸ë³´ìœ  + ì €í‰ì  ì‹œì¥ {len(urgent_parking)}ê°œ\")\n",
    "    print(f\"   - ì˜ˆìƒ íš¨ê³¼: ì ‘ê·¼ì„± ê°œì„ ìœ¼ë¡œ ê³ ê° ë§Œì¡±ë„ 0.3-0.5ì  í–¥ìƒ ì˜ˆìƒ\")\n",
    "    print(f\"   - ìš°ì„  ëŒ€ìƒ ì‹œì¥:\")\n",
    "    for i, (_, market) in enumerate(urgent_parking.head(3).iterrows(), 1):\n",
    "        print(f\"     {i}. {market['ì‹œì¥ëª…']} (í˜„ì¬ í‰ì : {market['í‰ì ']:.1f})\")\n",
    "    \n",
    "    # ë‹¨ê¸° ì •ì±… 2: ë””ì§€í„¸ ë§ˆì¼€íŒ… ì§€ì›\n",
    "    print(f\"\\nğŸ“± 1-2. ë””ì§€í„¸ ë§ˆì¼€íŒ… ì§€ì› ì‚¬ì—…\")\n",
    "    low_review_markets = df[df['ë¦¬ë·°ìˆ˜'] < df['ë¦¬ë·°ìˆ˜'].median()].sort_values('ë¦¬ë·°ìˆ˜')\n",
    "    print(f\"   - ëŒ€ìƒ: ì˜¨ë¼ì¸ ë…¸ì¶œë„ê°€ ë‚®ì€ ì‹œì¥ {len(low_review_markets)}ê°œ\")\n",
    "    print(f\"   - ë‚´ìš©: ë„¤ì´ë²„/ì¹´ì¹´ì˜¤ë§µ ë“±ë¡, SNS ë§ˆì¼€íŒ… êµìœ¡, ì˜¨ë¼ì¸ í™ë³´ ì§€ì›\")\n",
    "    print(f\"   - ì˜ˆìƒ íš¨ê³¼: ì˜¨ë¼ì¸ ì¸ì§€ë„ í–¥ìƒìœ¼ë¡œ ë°©ë¬¸ê° 20-30% ì¦ê°€\")\n",
    "    \n",
    "    print(f\"\\nğŸ—ï¸ 2. ì¤‘ê¸° ì •ì±… ì œì•ˆ (3-5ë…„)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # ì¤‘ê¸° ì •ì±… 1: ì•„ì¼€ì´ë“œ ì„¤ì¹˜\n",
    "    urgent_arcade = df[(df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ì—†ìŒ') & (df['í‰ì '] < 4.0)].sort_values('í‰ì ')\n",
    "    print(f\"ğŸ¢ 2-1. ì•„ì¼€ì´ë“œ ë° ì‹¤ë‚´í™” ì‚¬ì—…\")\n",
    "    print(f\"   - ëŒ€ìƒ: ì•„ì¼€ì´ë“œ ë¯¸ë³´ìœ  ì‹œì¥ {len(urgent_arcade)}ê°œ\")\n",
    "    print(f\"   - ë‚´ìš©: ì§€ë¶• ì„¤ì¹˜, ì‹¤ë‚´ í™˜ê²½ ì¡°ì„±, ëƒ‰ë‚œë°© ì‹œì„¤ êµ¬ì¶•\")\n",
    "    print(f\"   - ì˜ˆìƒ íš¨ê³¼: ë‚ ì”¨ ì˜í–¥ ìµœì†Œí™”ë¡œ ì—°ì¤‘ ì•ˆì •ì  ìš´ì˜\")\n",
    "    \n",
    "    # ì¤‘ê¸° ì •ì±… 2: ì‹œì„¤ í˜„ëŒ€í™”\n",
    "    old_low_rating = df[(df['ì‹œì¥ì—°ë ¹'] > 40) & (df['í‰ì '] < 3.5)]\n",
    "    print(f\"\\nğŸ”§ 2-2. ì‹œì„¤ í˜„ëŒ€í™” ì‚¬ì—…\")\n",
    "    print(f\"   - ëŒ€ìƒ: ë…¸í›„ + ì €í‰ì  ì‹œì¥ {len(old_low_rating)}ê°œ\")\n",
    "    print(f\"   - ë‚´ìš©: í™”ì¥ì‹¤ ê°œì„ , ë°”ë‹¥ ì •ë¹„, ì¡°ëª… êµì²´, ì•ˆì „ì‹œì„¤ ë³´ê°•\")\n",
    "    print(f\"   - ì˜ˆìƒ íš¨ê³¼: ì¾Œì í•œ í™˜ê²½ ì¡°ì„±ìœ¼ë¡œ ê³ ê° ë§Œì¡±ë„ í–¥ìƒ\")\n",
    "    \n",
    "    print(f\"\\nğŸŒŸ 3. ì¥ê¸° ì •ì±… ì œì•ˆ (5-10ë…„)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # ì¥ê¸° ì •ì±… 1: íŠ¹í™” ì‹œì¥ ìœ¡ì„±\n",
    "    print(f\"ğŸ¨ 3-1. íŠ¹í™” ì‹œì¥ ìœ¡ì„± ì‚¬ì—…\")\n",
    "    specialty_candidates = df[df['í‰ì '] >= 4.0].sort_values('í‰ì ', ascending=False)\n",
    "    print(f\"   - ëŒ€ìƒ: ê³ í‰ì  ì‹œì¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŠ¹í™” ë¸Œëœë“œ ê°œë°œ\")\n",
    "    print(f\"   - ë‚´ìš©: ì§€ì—­ íŠ¹ì‚°í’ˆ, ë¬¸í™” ì½˜í…ì¸ ì™€ ì—°ê³„í•œ í…Œë§ˆ ì‹œì¥ ì¡°ì„±\")\n",
    "    print(f\"   - ìš°ìˆ˜ ì‹œì¥ í™œìš©:\")\n",
    "    for i, (_, market) in enumerate(specialty_candidates.head(3).iterrows(), 1):\n",
    "        print(f\"     {i}. {market['ì‹œì¥ëª…']} (í‰ì : {market['í‰ì ']:.1f}, ì£¼ìš”ìƒí’ˆ: {market['ì£¼ìš”ìƒí’ˆ']})\")\n",
    "    \n",
    "    # ì¥ê¸° ì •ì±… 2: ìŠ¤ë§ˆíŠ¸ ì‹œì¥ êµ¬ì¶•\n",
    "    print(f\"\\nğŸ’» 3-2. ìŠ¤ë§ˆíŠ¸ ì‹œì¥ êµ¬ì¶• ì‚¬ì—…\")\n",
    "    print(f\"   - ë‚´ìš©: IoT ê¸°ë°˜ ì‹œì„¤ ê´€ë¦¬, ëª¨ë°”ì¼ ê²°ì œ ì‹œìŠ¤í…œ, ë°°ì†¡ ì„œë¹„ìŠ¤\")\n",
    "    print(f\"   - ëŒ€ìƒ: ëŒ€í˜• ì‹œì¥ë¶€í„° ë‹¨ê³„ì  í™•ì‚°\")\n",
    "    large_markets = df[df['ê·œëª¨ë¶„ë¥˜'] == 'ëŒ€í˜•'].sort_values('í‰ì ', ascending=False)\n",
    "    print(f\"   - 1ë‹¨ê³„ ëŒ€ìƒ (ëŒ€í˜• ì‹œì¥): {len(large_markets)}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ’° 4. ì˜ˆì‚° ë° ìš°ì„ ìˆœìœ„\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # ë¹„ìš© íš¨ê³¼ ë¶„ì„\n",
    "    print(f\"ğŸ“ˆ 4-1. íˆ¬ì ìš°ì„ ìˆœìœ„ (ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼)\")\n",
    "    print(f\"   1ìˆœìœ„: ì£¼ì°¨ì¥ í™•ì¶© (ì €ë¹„ìš©, ì¦‰ì‹œ íš¨ê³¼)\")\n",
    "    print(f\"   2ìˆœìœ„: ë””ì§€í„¸ ë§ˆì¼€íŒ… ì§€ì› (ì €ë¹„ìš©, ë‹¨ê¸° íš¨ê³¼)\")\n",
    "    print(f\"   3ìˆœìœ„: ì‹œì„¤ í˜„ëŒ€í™” (ì¤‘ë¹„ìš©, ì¤‘ê¸° íš¨ê³¼)\")\n",
    "    print(f\"   4ìˆœìœ„: ì•„ì¼€ì´ë“œ ì„¤ì¹˜ (ê³ ë¹„ìš©, ì¥ê¸° íš¨ê³¼)\")\n",
    "    \n",
    "    # ì˜ˆìƒ ì˜ˆì‚°\n",
    "    print(f\"\\nğŸ’µ 4-2. ì˜ˆìƒ ì˜ˆì‚° (ê°œëµì  ì¶”ì •)\")\n",
    "    print(f\"   - ì£¼ì°¨ì¥ í™•ì¶©: ì‹œì¥ë‹¹ 2-5ì–µì› Ã— {len(urgent_parking)}ê°œ = {len(urgent_parking)*3:.0f}ì–µì›\")\n",
    "    print(f\"   - ë””ì§€í„¸ ë§ˆì¼€íŒ…: ì‹œì¥ë‹¹ 500ë§Œì› Ã— {total_markets}ê°œ = {total_markets*0.05:.0f}ì–µì›\")\n",
    "    print(f\"   - ì‹œì„¤ í˜„ëŒ€í™”: ì‹œì¥ë‹¹ 5-10ì–µì› Ã— {len(old_low_rating)}ê°œ = {len(old_low_rating)*7:.0f}ì–µì›\")\n",
    "    print(f\"   - ì•„ì¼€ì´ë“œ ì„¤ì¹˜: ì‹œì¥ë‹¹ 10-20ì–µì› Ã— {len(urgent_arcade)}ê°œ = {len(urgent_arcade)*15:.0f}ì–µì›\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ 5. ì„±ê³¼ ì§€í‘œ ë° ëª¨ë‹ˆí„°ë§\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   - ê³ ê° ë§Œì¡±ë„: í‰ê·  í‰ì  {df['í‰ì '].mean():.2f}ì  â†’ 4.0ì  ëª©í‘œ\")\n",
    "    print(f\"   - ë°©ë¬¸ê° ì¦ê°€ìœ¨: ë¦¬ë·° ìˆ˜ ê¸°ì¤€ ì—° 20% ì¦ê°€ ëª©í‘œ\")\n",
    "    print(f\"   - ì‹œì„¤ ê°œì„ ìœ¨: ì£¼ì°¨ì¥ ë³´ìœ ìœ¨ 70% â†’ 90% ëª©í‘œ\")\n",
    "    print(f\"   - ë””ì§€í„¸í™”ìœ¨: ì˜¨ë¼ì¸ ë¦¬ë·° ë³´ìœ  ì‹œì¥ 100% ë‹¬ì„±\")\n",
    "    \n",
    "    return {\n",
    "        'urgent_parking': urgent_parking,\n",
    "        'low_review_markets': low_review_markets,\n",
    "        'old_low_rating': old_low_rating,\n",
    "        'specialty_candidates': specialty_candidates\n",
    "    }\n",
    "\n",
    "# ì •ì±… ì œì•ˆ ìƒì„±\n",
    "policy_data = generate_policy_recommendations(final_market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ë°ì´í„° ì €ì¥ (CSV íŒŒì¼ ìƒì„±)\n",
    "\n",
    "def save_analysis_results(df, policy_data):\n",
    "    \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì €ì¥\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # 1. ì „ì²´ ë¶„ì„ ë°ì´í„° ì €ì¥\n",
    "        final_filename = 'ì „í†µì‹œì¥_ë¶„ì„ê²°ê³¼_ìµœì¢….csv'\n",
    "        df.to_csv(final_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… ì „ì²´ ë¶„ì„ ë°ì´í„° ì €ì¥: {final_filename}\")\n",
    "        \n",
    "        # 2. ì •ì±… ëŒ€ìƒ ì‹œì¥ ë°ì´í„° ì €ì¥\n",
    "        if len(policy_data['urgent_parking']) > 0:\n",
    "            parking_filename = 'ì£¼ì°¨ì¥_í™•ì¶©_ëŒ€ìƒì‹œì¥.csv'\n",
    "            policy_data['urgent_parking'].to_csv(parking_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… ì£¼ì°¨ì¥ í™•ì¶© ëŒ€ìƒ ì €ì¥: {parking_filename}\")\n",
    "        \n",
    "        if len(policy_data['old_low_rating']) > 0:\n",
    "            renovation_filename = 'ì‹œì„¤_í˜„ëŒ€í™”_ëŒ€ìƒì‹œì¥.csv'\n",
    "            policy_data['old_low_rating'].to_csv(renovation_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… ì‹œì„¤ í˜„ëŒ€í™” ëŒ€ìƒ ì €ì¥: {renovation_filename}\")\n",
    "        \n",
    "        # 3. ìš°ìˆ˜ ì‹œì¥ ë°ì´í„° ì €ì¥\n",
    "        if len(policy_data['specialty_candidates']) > 0:\n",
    "            specialty_filename = 'íŠ¹í™”ì‹œì¥_ìœ¡ì„±_í›„ë³´.csv'\n",
    "            policy_data['specialty_candidates'].to_csv(specialty_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… íŠ¹í™”ì‹œì¥ í›„ë³´ ì €ì¥: {specialty_filename}\")\n",
    "        \n",
    "        # 4. ìš”ì•½ í†µê³„ ì €ì¥\n",
    "        summary_stats = {\n",
    "            'êµ¬ë¶„': ['ì „ì²´ ì‹œì¥ ìˆ˜', 'í‰ê·  í‰ì ', 'í‰ê·  ë¦¬ë·°ìˆ˜', 'ì£¼ì°¨ì¥ ë³´ìœ ìœ¨(%)', 'ì•„ì¼€ì´ë“œ ë³´ìœ ìœ¨(%)', \n",
    "                   'í‰ê·  ì‹œì„¤ì ìˆ˜', 'ê°œì„  í•„ìš” ì‹œì¥ ìˆ˜', 'ê³ í‰ì  ì‹œì¥ ìˆ˜(4.0 ì´ìƒ)'],\n",
    "            'ê°’': [\n",
    "                len(df),\n",
    "                round(df['í‰ì '].mean(), 2),\n",
    "                round(df['ë¦¬ë·°ìˆ˜'].mean(), 0),\n",
    "                round((df['ì£¼ì°¨ì¥ìœ ë¬´'] == 'ìˆìŒ').mean() * 100, 1),\n",
    "                round((df['ì•„ì¼€ì´ë“œìœ ë¬´'] == 'ìˆìŒ').mean() * 100, 1),\n",
    "                round(df['ì‹œì„¤ì ìˆ˜'].mean(), 1),\n",
    "                len(df[df['í‰ì '] < 3.5]),\n",
    "                len(df[df['í‰ì '] >= 4.0])\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_stats)\n",
    "        summary_filename = 'ë¶„ì„_ìš”ì•½í†µê³„.csv'\n",
    "        summary_df.to_csv(summary_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… ìš”ì•½ í†µê³„ ì €ì¥: {summary_filename}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:\")\n",
    "        print(f\"   1. {final_filename} - ì „ì²´ ë¶„ì„ ê²°ê³¼\")\n",
    "        print(f\"   2. {summary_filename} - ìš”ì•½ í†µê³„\")\n",
    "        print(f\"   3. {parking_filename} - ì£¼ì°¨ì¥ í™•ì¶© ëŒ€ìƒ\")\n",
    "        print(f\"   4. {renovation_filename} - ì‹œì„¤ í˜„ëŒ€í™” ëŒ€ìƒ\")\n",
    "        print(f\"   5. {specialty_filename} - íŠ¹í™”ì‹œì¥ í›„ë³´\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return False\n",
    "\n",
    "# ë°ì´í„° ì €ì¥ ì‹¤í–‰\n",
    "save_success = save_analysis_results(final_market_data, policy_data)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ“ ê²°ë¡  ë° ìš”ì•½\n",
    "\n",
    "### ì£¼ìš” ë¶„ì„ ê²°ê³¼\n",
    "1. **ì‹œì„¤ í˜„í™©ê³¼ ê³ ê° ë§Œì¡±ë„ì˜ ìƒê´€ê´€ê³„**: ì£¼ì°¨ì¥, ì•„ì¼€ì´ë“œ ë“± í¸ì˜ì‹œì„¤ì´ ê³ ê° í‰ì ì— ê¸ì •ì  ì˜í–¥\n",
    "2. **ì§€ì—­ë³„ ê²©ì°¨**: ìˆ˜ë„ê¶Œê³¼ ì§€ë°© ê°„ ì‹œì„¤ ìˆ˜ì¤€ ë° ë§Œì¡±ë„ ì°¨ì´ ì¡´ì¬\n",
    "3. **ì‹œì¥ ì—°ë ¹ì˜ ì˜í–¥**: ë…¸í›„ ì‹œì¥ì¼ìˆ˜ë¡ í‰ì ì´ ë‚®ì€ ê²½í–¥\n",
    "4. **ê·œëª¨ë³„ íŠ¹ì„±**: ì¤‘í˜• ê·œëª¨ ì‹œì¥ì´ ê°€ì¥ ë†’ì€ ë§Œì¡±ë„ë¥¼ ë³´ì„\n",
    "\n",
    "### ì •ì±… ì œì•ˆ ìš°ì„ ìˆœìœ„\n",
    "1. **ë‹¨ê¸° (1-2ë…„)**: ì£¼ì°¨ì¥ í™•ì¶©, ë””ì§€í„¸ ë§ˆì¼€íŒ… ì§€ì›\n",
    "2. **ì¤‘ê¸° (3-5ë…„)**: ì•„ì¼€ì´ë“œ ì„¤ì¹˜, ì‹œì„¤ í˜„ëŒ€í™”\n",
    "3. **ì¥ê¸° (5-10ë…„)**: íŠ¹í™” ì‹œì¥ ìœ¡ì„±, ìŠ¤ë§ˆíŠ¸ ì‹œì¥ êµ¬ì¶•\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- ê³ ê° ë§Œì¡±ë„ í–¥ìƒ (í‰ê·  í‰ì  4.0ì  ëª©í‘œ)\n",
    "- ì „í†µì‹œì¥ ë°©ë¬¸ê° ì¦ê°€ (ì—° 20-30% ì¦ê°€ ì˜ˆìƒ)\n",
    "- ì§€ì—­ ê²½ì œ í™œì„±í™” ë° ì „í†µì‹œì¥ ê²½ìŸë ¥ ê°•í™”\n",
    "\n",
    "---\n",
    "\n",
    "**â€» ë³¸ ë¶„ì„ì€ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹œì—°ìš© ê²°ê³¼ì…ë‹ˆë‹¤. ì‹¤ì œ ì •ì±… ìˆ˜ë¦½ ì‹œì—ëŠ” ê³µê³µë°ì´í„°í¬í„¸ì˜ ì‹¤ì œ ë°ì´í„°ì™€ í˜„ì¥ ì¡°ì‚¬ë¥¼ í†µí•œ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
