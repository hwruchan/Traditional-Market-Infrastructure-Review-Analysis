import csv
import re
from collections import defaultdict

def read_csv_with_encoding(filename, encodings=['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']):
    """ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ì„ ì½ì–´ë³´ëŠ” í•¨ìˆ˜"""
    for encoding in encodings:
        try:
            with open(filename, 'r', encoding=encoding, newline='') as file:
                reader = csv.reader(file)
                data = list(reader)
                print(f"âœ… {filename} íŒŒì¼ì„ {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")
                return data, encoding
        except (UnicodeDecodeError, UnicodeError):
            continue
    
    raise Exception(f"íŒŒì¼ {filename}ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§€ì›í•˜ëŠ” ì¸ì½”ë”©: {encodings}")

def clean_market_name(name):
    """ì‹œì¥ëª… ì •ì œ í•¨ìˆ˜"""
    if not name:
        return ""
    
    # íŠ¹ìˆ˜ ì˜ˆì™¸ ì²˜ë¦¬: 'ìš´ìˆ˜ëŒ€í†µ! ìƒê±°ì§„ì²œì „í†µì‹œì¥' â†’ 'ìš´ìˆ˜ëŒ€í†µ ìƒê±°ì§„ì²œì „í†µì‹œì¥'
    if 'ìš´ìˆ˜ëŒ€í†µ!' in name and 'ìƒê±°ì§„ì²œì „í†µì‹œì¥' in name:
        name = name.replace('ìš´ìˆ˜ëŒ€í†µ!', 'ìš´ìˆ˜ëŒ€í†µ')
    
    # ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš© ì œê±°
    name = re.sub(r'\([^)]*\)', '', name)
    
    # ê³µë°± ì •ë¦¬
    name = ' '.join(name.split())
    
    return name.strip()

def standardize_region(address):
    """ì§€ì—­ëª… í‘œì¤€í™” - ê°•ì›íŠ¹ë³„ìì¹˜ë„ â†’ ê°•ì›ë„, ì „ë¶íŠ¹ë³„ìì¹˜ë„ â†’ ì „ë¼ë¶ë„"""
    if not address:
        return address
    
    # ì§€ì—­ëª… í‘œì¤€í™”
    address = address.replace('ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê°•ì›ë„')
    address = address.replace('ì „ë¶íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë¶ë„')
    
    return address

def normalize_address(address):
    """ì£¼ì†Œ ì •ê·œí™” - ë¹„êµë¥¼ ìœ„í•œ ì£¼ì†Œ ì •ì œ"""
    if not address:
        return ""
    
    # ì§€ì—­ëª… í‘œì¤€í™”
    address = standardize_region(address)
    
    # ê³µë°± ì •ë¦¬ ë° ì†Œë¬¸ì ë³€í™˜
    address = re.sub(r'\s+', ' ', address).strip()
    
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ë¹„êµìš©)
    address = re.sub(r'[^\w\sê°€-í£]', '', address)
    
    return address

def extract_key_address_parts(address):
    """ì£¼ì†Œì—ì„œ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ (ì‹œêµ°êµ¬ + ë™/ì/ë©´)"""
    if not address:
        return ""
    
    # ì‹œêµ°êµ¬ì™€ ë™/ì/ë©´ íŒ¨í„´ ì°¾ê¸°
    pattern = r'([\w]+ì‹œ|[\w]+êµ°|[\w]+êµ¬)\s*([\w]+ë™|[\w]+ì|[\w]+ë©´)'
    match = re.search(pattern, address)
    
    if match:
        return f"{match.group(1)} {match.group(2)}"
    
    # ì‹œêµ°êµ¬ë§Œ ìˆëŠ” ê²½ìš°
    sigungu_pattern = r'([\w]+ì‹œ|[\w]+êµ°|[\w]+êµ¬)'
    match = re.search(sigungu_pattern, address)
    if match:
        return match.group(1)
    
    return ""

def create_final_header():
    """ìµœì¢… í—¤ë” ìƒì„±"""
    
    # ê¸°ë³¸ ì •ë³´ ì»¬ëŸ¼ë“¤
    basic_columns = [
        'ì‹œì¥ì½”ë“œ',
        'ì‹œì¥ëª…',
        'ì§€ë²ˆì£¼ì†Œ',
        'ë„ë¡œëª…ì£¼ì†Œ',
        'ì‹œë„',
        'ì‹œêµ°êµ¬',
        'ì‹œì¥ê°œì„¤ì£¼ê¸°',
        'ì í¬ìˆ˜',
        'ê°œì„¤ì—°ë„',
        'ì·¨ê¸‰í’ˆëª©'
    ]
    
    # ì²« ë²ˆì§¸ íŒŒì¼ì˜ ì‹œì„¤ ë³´ìœ ì—¬ë¶€ ì»¬ëŸ¼ë“¤
    facility_columns_file1 = [
        'ì•„ì¼€ì´ë“œ',
        'ì—˜ë¦¬ë² ì´í„°/ì—ìŠ¤ì»¬ë ˆì´í„°',
        'ê³ ê°ì§€ì›ì„¼í„°',
        'ìŠ¤í”„ë§ì¿¨ëŸ¬',
        'í™”ì¬ê°ì§€ê¸°',
        'ìœ ì•„ë†€ì´ë°©',
        'ì¢…í•©ì½œì„¼í„°',
        'ê³ ê°íœ´ê²Œì‹¤',
        'ìˆ˜ìœ ì„¼í„°',
        'ë¬¼í’ˆë³´ê´€í•¨',
        'ìì „ê±°ë³´ê´€í•¨',
        'ì²´ìœ¡ì‹œì„¤',
        'ê°„ì´ë„ì„œê´€',
        'ì‡¼í•‘ì¹´íŠ¸',
        'ì™¸êµ­ì¸ì•ˆë‚´ì„¼í„°',
        'ê³ ê°ë™ì„ í†µë¡œ',
        'ë°©ì†¡ì„¼í„°',
        'ë¬¸í™”êµì‹¤',
        'ê³µë™ë¬¼ë¥˜ì°½ê³ ',
        'ì‹œì¥ì „ìš©ê³ ê°ì£¼ì°¨ì¥',
        'êµìœ¡ì¥',
        'íšŒì˜ì‹¤',
        'ìë™ì‹¬ì¥ì¶©ê²©ê¸°'
    ]
    
    # ë‘ ë²ˆì§¸ íŒŒì¼ì˜ ì‹œì„¤ ë³´ìœ ì—¬ë¶€ ì»¬ëŸ¼ë“¤
    facility_columns_file2 = [
        'ê³µì¤‘í™”ì¥ì‹¤',
        'ì£¼ì°¨ì¥'
    ]
    
    # ìœ„ì¹˜ ë° ì—°ë½ì²˜ ì •ë³´
    location_contact_columns = [
        'ìœ„ë„',
        'ê²½ë„',
        'ì „í™”ë²ˆí˜¸'
    ]
    
    # ì „ì²´ í—¤ë” êµ¬ì„±
    header = basic_columns + facility_columns_file1 + facility_columns_file2 + location_contact_columns
    
    return header

def get_value_from_file(row, header, column_name):
    """íŒŒì¼ì—ì„œ íŠ¹ì • ì»¬ëŸ¼ ê°’ ê°€ì ¸ì˜¤ê¸°"""
    if not row or not column_name or column_name not in header:
        return ""
    try:
        idx = header.index(column_name)
        return row[idx] if len(row) > idx else ""
    except (ValueError, IndexError):
        return ""

def smart_merge_csv_files():
    """ì‹œì¥ëª… ìš°ì„ , ì¤‘ë³µ ì‹œ ì£¼ì†Œ ë§¤ì¹­í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ í•©ë³‘"""
    
    print("ğŸš€ ìŠ¤ë§ˆíŠ¸ ì‹œì¥ ë°ì´í„° í•©ë³‘ ì‹œì‘...")
    print("ğŸ“‹ ë§¤ì¹­ ì „ëµ: ì‹œì¥ëª… ìš°ì„  â†’ ë„ë¡œëª…ì£¼ì†Œ â†’ ì§€ë²ˆì£¼ì†Œ")
    
    try:
        # ì²« ë²ˆì§¸ íŒŒì¼ ì½ê¸°
        print("\nğŸ“ ì²« ë²ˆì§¸ íŒŒì¼ ì½ëŠ” ì¤‘...")
        file1_data, encoding1 = read_csv_with_encoding('ì†Œìƒê³µì¸ì‹œì¥ì§„í¥ê³µë‹¨_ì „í†µì‹œì¥í˜„í™©_20240719.csv')
        print(f"âœ… ì²« ë²ˆì§¸ íŒŒì¼: {len(file1_data)}ê°œ í–‰, ì¸ì½”ë”©: {encoding1}")
        
        # ë‘ ë²ˆì§¸ íŒŒì¼ ì½ê¸°
        print("ğŸ“ ë‘ ë²ˆì§¸ íŒŒì¼ ì½ëŠ” ì¤‘...")
        file2_data, encoding2 = read_csv_with_encoding('ì „êµ­ì „í†µì‹œì¥í‘œì¤€ë°ì´í„°.csv')
        print(f"âœ… ë‘ ë²ˆì§¸ íŒŒì¼: {len(file2_data)}ê°œ í–‰, ì¸ì½”ë”©: {encoding2}")
        
        if not file1_data or not file2_data:
            print("âŒ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return
        
        # í—¤ë” ì¶”ì¶œ
        header1 = file1_data[0] if file1_data else []
        header2 = file2_data[0] if file2_data else []
        
        print(f"\nğŸ” ì²« ë²ˆì§¸ íŒŒì¼ ì»¬ëŸ¼ ìˆ˜: {len(header1)}")
        print(f"ğŸ” ë‘ ë²ˆì§¸ íŒŒì¼ ì»¬ëŸ¼ ìˆ˜: {len(header2)}")
        
        # ìµœì¢… í—¤ë” ìƒì„±
        final_header = create_final_header()
        
        print(f"\nğŸ“‹ ìµœì¢… í—¤ë” ({len(final_header)}ê°œ ì»¬ëŸ¼):")
        for i, col in enumerate(final_header):
            print(f"   {i+1:2d}. {col}")
        
        # ì²« ë²ˆì§¸ íŒŒì¼ ë°ì´í„° êµ¬ì¡°í™”
        print(f"\nğŸ”„ ì²« ë²ˆì§¸ íŒŒì¼ ë°ì´í„° êµ¬ì¡°í™”...")
        file1_markets = {}
        file1_name_groups = defaultdict(list)  # ê°™ì€ ì´ë¦„ì˜ ì‹œì¥ë“¤ ê·¸ë£¹í™”
        
        for i, row in enumerate(file1_data[1:], 1):
            if len(row) > 1:
                market_code = row[0] if len(row) > 0 else ""
                market_name = clean_market_name(row[1]) if len(row) > 1 else ""
                road_addr = get_value_from_file(row, header1, 'ë„ë¡œëª…ì£¼ì†Œ')
                jibun_addr = get_value_from_file(row, header1, 'ì§€ë²ˆì£¼ì†Œ')
                
                if market_code and market_name:
                    market_info = {
                        'row': row,
                        'market_code': market_code,
                        'market_name': market_name,
                        'road_addr': road_addr,
                        'jibun_addr': jibun_addr,
                        'road_addr_norm': normalize_address(road_addr),
                        'jibun_addr_norm': normalize_address(jibun_addr),
                        'addr_key': extract_key_address_parts(road_addr if road_addr and road_addr != '0' else jibun_addr)
                    }
                    
                    file1_markets[market_code] = market_info
                    file1_name_groups[market_name].append(market_info)
        
        print(f"âœ… ì²« ë²ˆì§¸ íŒŒì¼: {len(file1_markets)}ê°œ ì‹œì¥ êµ¬ì¡°í™” ì™„ë£Œ")
        
        # ë‘ ë²ˆì§¸ íŒŒì¼ ë°ì´í„° êµ¬ì¡°í™”
        print(f"ğŸ”„ ë‘ ë²ˆì§¸ íŒŒì¼ ë°ì´í„° êµ¬ì¡°í™”...")
        file2_markets = []
        file2_name_groups = defaultdict(list)
        
        for i, row in enumerate(file2_data[1:], 1):
            if len(row) > 0:
                market_name = clean_market_name(row[0]) if len(row) > 0 else ""
                road_addr = get_value_from_file(row, header2, 'ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ')
                jibun_addr = get_value_from_file(row, header2, 'ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ')
                
                if market_name:
                    market_info = {
                        'row': row,
                        'market_name': market_name,
                        'road_addr': road_addr,
                        'jibun_addr': jibun_addr,
                        'road_addr_norm': normalize_address(road_addr),
                        'jibun_addr_norm': normalize_address(jibun_addr),
                        'addr_key': extract_key_address_parts(road_addr if road_addr else jibun_addr),
                        'matched': False
                    }
                    
                    file2_markets.append(market_info)
                    file2_name_groups[market_name].append(market_info)
        
        print(f"âœ… ë‘ ë²ˆì§¸ íŒŒì¼: {len(file2_markets)}ê°œ ì‹œì¥ êµ¬ì¡°í™” ì™„ë£Œ")
        
        # ë§¤ì¹­ ê³¼ì •
        print(f"\nğŸ”— ë§¤ì¹­ ê³¼ì • ì‹œì‘...")
        matches = []
        
        # 1ë‹¨ê³„: ì‹œì¥ëª…ì´ ê³ ìœ í•œ ê²½ìš° ì§ì ‘ ë§¤ì¹­
        print(f"1ï¸âƒ£ ê³ ìœ  ì‹œì¥ëª… ë§¤ì¹­...")
        unique_name_matches = 0
        
        for name, file1_group in file1_name_groups.items():
            if len(file1_group) == 1 and name in file2_name_groups and len(file2_name_groups[name]) == 1:
                file1_market = file1_group[0]
                file2_market = file2_name_groups[name][0]
                
                matches.append((file1_market, file2_market))
                file2_market['matched'] = True
                unique_name_matches += 1
        
        print(f"   âœ… ê³ ìœ  ì‹œì¥ëª… ë§¤ì¹­: {unique_name_matches}ê°œ")
        
        # 2ë‹¨ê³„: ì¤‘ë³µ ì‹œì¥ëª…ì˜ ê²½ìš° ì£¼ì†Œë¡œ ë§¤ì¹­
        print(f"2ï¸âƒ£ ì¤‘ë³µ ì‹œì¥ëª… ì£¼ì†Œ ë§¤ì¹­...")
        address_matches = 0
        
        for name, file1_group in file1_name_groups.items():
            if len(file1_group) > 1 or (name in file2_name_groups and len(file2_name_groups[name]) > 1):
                if name in file2_name_groups:
                    file2_group = [m for m in file2_name_groups[name] if not m['matched']]
                    
                    for file1_market in file1_group:
                        best_match = None
                        best_score = 0
                        
                        for file2_market in file2_group:
                            if file2_market['matched']:
                                continue
                            
                            score = 0
                            
                            # ë„ë¡œëª…ì£¼ì†Œ ë¹„êµ
                            if (file1_market['road_addr_norm'] and file2_market['road_addr_norm'] and 
                                file1_market['road_addr_norm'] == file2_market['road_addr_norm']):
                                score += 100
                            
                            # ì§€ë²ˆì£¼ì†Œ ë¹„êµ
                            elif (file1_market['jibun_addr_norm'] and file2_market['jibun_addr_norm'] and 
                                  file1_market['jibun_addr_norm'] == file2_market['jibun_addr_norm']):
                                score += 90
                            
                            # ì£¼ì†Œ í•µì‹¬ ë¶€ë¶„ ë¹„êµ
                            elif (file1_market['addr_key'] and file2_market['addr_key'] and 
                                  file1_market['addr_key'] == file2_market['addr_key']):
                                score += 70
                            
                            # ë¶€ë¶„ ì£¼ì†Œ ë§¤ì¹­
                            elif (file1_market['road_addr_norm'] and file2_market['road_addr_norm']):
                                if file1_market['addr_key'] in file2_market['road_addr_norm'] or file2_market['addr_key'] in file1_market['road_addr_norm']:
                                    score += 50
                            
                            if score > best_score:
                                best_score = score
                                best_match = file2_market
                        
                        if best_match and best_score >= 50:  # ìµœì†Œ ì ìˆ˜ ê¸°ì¤€
                            matches.append((file1_market, best_match))
                            best_match['matched'] = True
                            address_matches += 1
        
        print(f"   âœ… ì£¼ì†Œ ë§¤ì¹­: {address_matches}ê°œ")
        
        # 3ë‹¨ê³„: ë§¤ì¹­ë˜ì§€ ì•Šì€ ì‹œì¥ë“¤ ì²˜ë¦¬
        print(f"3ï¸âƒ£ ë§¤ì¹­ë˜ì§€ ì•Šì€ ì‹œì¥ ì²˜ë¦¬...")
        unmatched_file1 = []
        unmatched_file2 = [m for m in file2_markets if not m['matched']]
        
        for market_code, market_info in file1_markets.items():
            if not any(market_info == match[0] for match in matches):
                unmatched_file1.append(market_info)
        
        print(f"   âš ï¸  ë§¤ì¹­ë˜ì§€ ì•Šì€ ì²« ë²ˆì§¸ íŒŒì¼ ì‹œì¥: {len(unmatched_file1)}ê°œ")
        print(f"   âš ï¸  ë§¤ì¹­ë˜ì§€ ì•Šì€ ë‘ ë²ˆì§¸ íŒŒì¼ ì‹œì¥: {len(unmatched_file2)}ê°œ")
        
        # ìµœì¢… ë°ì´í„° ìƒì„±
        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„° ìƒì„±...")
        final_data = [final_header]
        
        # ë§¤ì¹­ëœ ë°ì´í„° ì²˜ë¦¬
        for file1_market, file2_market in matches:
            final_row = create_merged_row(file1_market, file2_market, header1, header2, final_header)
            final_data.append(final_row)
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì€ ì²« ë²ˆì§¸ íŒŒì¼ ë°ì´í„° ì¶”ê°€
        for file1_market in unmatched_file1:
            final_row = create_merged_row(file1_market, None, header1, header2, final_header)
            final_data.append(final_row)
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì€ ë‘ ë²ˆì§¸ íŒŒì¼ ë°ì´í„° ì¶”ê°€
        for file2_market in unmatched_file2:
            final_row = create_merged_row(None, file2_market, header1, header2, final_header)
            final_data.append(final_row)
        
        # ê²°ê³¼ ì €ì¥
        output_filename = 'ì „í†µì‹œì¥_ìµœì¢…í•©ë³‘ë°ì´í„°.csv'
        with open(output_filename, 'w', encoding='utf-8-sig', newline='') as file:
            writer = csv.writer(file)
            writer.writerows(final_data)
        
        # ë§¤ì¹­ëœ ë°ì´í„°ë§Œ ë³„ë„ ì €ì¥
        matched_filename = 'ì „í†µì‹œì¥_ìµœì¢…ë§¤ì¹­ë°ì´í„°.csv'
        matched_data = [final_header] + [create_merged_row(f1, f2, header1, header2, final_header) for f1, f2 in matches]
        with open(matched_filename, 'w', encoding='utf-8-sig', newline='') as file:
            writer = csv.writer(file)
            writer.writerows(matched_data)
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ‰ ìŠ¤ë§ˆíŠ¸ í•©ë³‘ ì™„ë£Œ!")
        print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"   1. {output_filename} - ì „ì²´ í•©ë³‘ ê²°ê³¼ ({len(final_data)-1}ê°œ ì‹œì¥)")
        print(f"   2. {matched_filename} - ë§¤ì¹­ëœ ë°ì´í„°ë§Œ ({len(matches)}ê°œ ì‹œì¥)")
        
        print(f"\nğŸ“Š ë§¤ì¹­ ê²°ê³¼:")
        print(f"   - ê³ ìœ  ì‹œì¥ëª… ë§¤ì¹­: {unique_name_matches}ê°œ")
        print(f"   - ì£¼ì†Œ ê¸°ë°˜ ë§¤ì¹­: {address_matches}ê°œ")
        print(f"   - ì´ ë§¤ì¹­: {len(matches)}ê°œ")
        print(f"   - ë§¤ì¹­ë¥ : {len(matches)}/{len(file1_markets)} = {len(matches)/len(file1_markets)*100:.1f}%")
        
        # ë§¤ì¹­ ì˜ˆì‹œ ì¶œë ¥
        print(f"\nğŸ” ë§¤ì¹­ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):")
        for i, (f1, f2) in enumerate(matches[:5]):
            print(f"   {i+1}. {f1['market_name']}")
            print(f"      íŒŒì¼1: {f1['market_code']} | {f1['road_addr'][:30]}...")
            print(f"      íŒŒì¼2: {f2['road_addr'][:30]}...")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def create_merged_row(file1_market, file2_market, header1, header2, final_header):
    """ë‘ ì‹œì¥ ì •ë³´ë¥¼ í•©ë³‘í•˜ì—¬ ìµœì¢… í–‰ ìƒì„±"""
    
    final_row = []
    
    for col in final_header:
        value = ""
        
        if col == 'ì‹œì¥ì½”ë“œ':
            value = file1_market['market_code'] if file1_market else ""
        
        elif col == 'ì‹œì¥ëª…':
            if file1_market:
                value = file1_market['market_name']
            elif file2_market:
                value = file2_market['market_name']
        
        elif col == 'ì§€ë²ˆì£¼ì†Œ':
            if file1_market and file1_market['jibun_addr']:
                value = standardize_region(file1_market['jibun_addr'])
            elif file2_market and file2_market['jibun_addr']:
                value = standardize_region(file2_market['jibun_addr'])
        
        elif col == 'ë„ë¡œëª…ì£¼ì†Œ':
            if file1_market and file1_market['road_addr'] and file1_market['road_addr'] != '0':
                value = standardize_region(file1_market['road_addr'])
            elif file2_market and file2_market['road_addr']:
                value = standardize_region(file2_market['road_addr'])
        
        elif col == 'ì‹œë„':
            value = get_value_from_file(file1_market['row'], header1, 'ì‹œë„') if file1_market else ""
            if not value and file2_market:
                # ì£¼ì†Œì—ì„œ ì‹œë„ ì¶”ì¶œ
                addr = file2_market['road_addr'] if file2_market['road_addr'] else file2_market['jibun_addr']
                value = extract_sido_from_address(addr)
        
        elif col == 'ì‹œêµ°êµ¬':
            value = get_value_from_file(file1_market['row'], header1, 'ì‹œêµ°êµ¬') if file1_market else ""
            if not value and file2_market:
                # ì£¼ì†Œì—ì„œ ì‹œêµ°êµ¬ ì¶”ì¶œ
                addr = file2_market['road_addr'] if file2_market['road_addr'] else file2_market['jibun_addr']
                value = extract_sigungu_from_address(addr)
        
        elif col in ['ì‹œì¥ê°œì„¤ì£¼ê¸°', 'ì í¬ìˆ˜', 'ê°œì„¤ì—°ë„', 'ì·¨ê¸‰í’ˆëª©', 'ìœ„ë„', 'ê²½ë„', 'ì „í™”ë²ˆí˜¸']:
            # ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            if file2_market:
                if col == 'ì „í™”ë²ˆí˜¸':
                    value = get_value_from_file(file2_market['row'], header2, 'ì „í™”ë²ˆí˜¸')
                else:
                    value = get_value_from_file(file2_market['row'], header2, col)
        
        elif col in ['ê³µì¤‘í™”ì¥ì‹¤', 'ì£¼ì°¨ì¥']:
            # ë‘ ë²ˆì§¸ íŒŒì¼ì˜ ì‹œì„¤ ì •ë³´
            if file2_market:
                col_name = col + 'ë³´ìœ ì—¬ë¶€'
                value = get_value_from_file(file2_market['row'], header2, col_name)
        
        else:
            # ì²« ë²ˆì§¸ íŒŒì¼ì˜ ì‹œì„¤ ì •ë³´
            if file1_market:
                # ì»¬ëŸ¼ëª… ë§¤í•‘
                facility_mapping = {
                    'ì•„ì¼€ì´ë“œ': 'ì•„ì¼€ì´ë“œ ë³´ìœ  ì—¬ë¶€',
                    'ì—˜ë¦¬ë² ì´í„°/ì—ìŠ¤ì»¬ë ˆì´í„°': 'ì—˜ë¦¬ë² ì´í„°_ì—ìŠ¤ì»¬ë ˆì´í„°_ë³´ìœ ì—¬ë¶€',
                    'ê³ ê°ì§€ì›ì„¼í„°': 'ê³ ê°ì§€ì›ì„¼í„° ë³´ìœ  ì—¬ë¶€',
                    'ìŠ¤í”„ë§ì¿¨ëŸ¬': 'ìŠ¤í”„ë§ì¿¨ëŸ¬ ë³´ìœ  ì—¬ë¶€',
                    'í™”ì¬ê°ì§€ê¸°': 'í™”ì¬ê°ì§€ê¸° ë³´ìœ ì—¬ë¶€',
                    'ìœ ì•„ë†€ì´ë°©': 'ìœ ì•„ë†€ì´ë°©_ë³´ìœ ì—¬ë¶€',
                    'ì¢…í•©ì½œì„¼í„°': 'ì¢…í•©ì½œì„¼í„°_ë³´ìœ ì—¬ë¶€',
                    'ê³ ê°íœ´ê²Œì‹¤': 'ê³ ê°íœ´ê²Œì‹¤_ë³´ìœ ì—¬ë¶€',
                    'ìˆ˜ìœ ì„¼í„°': 'ìˆ˜ìœ ì„¼í„°_ë³´ìœ ì—¬ë¶€',
                    'ë¬¼í’ˆë³´ê´€í•¨': 'ë¬¼í’ˆë³´ê´€í•¨_ë³´ìœ ì—¬ë¶€',
                    'ìì „ê±°ë³´ê´€í•¨': 'ìì „ê±°ë³´ê´€í•¨_ë³´ìœ ì—¬ë¶€',
                    'ì²´ìœ¡ì‹œì„¤': 'ì²´ìœ¡ì‹œì„¤_ë³´ìœ ì—¬ë¶€',
                    'ê°„ì´ë„ì„œê´€': 'ê°„ì´ ë„ì„œê´€_ë³´ìœ ì—¬ë¶€',
                    'ì‡¼í•‘ì¹´íŠ¸': 'ì‡¼í•‘ì¹´íŠ¸_ë³´ìœ ì—¬ë¶€',
                    'ì™¸êµ­ì¸ì•ˆë‚´ì„¼í„°': 'ì™¸êµ­ì¸ ì•ˆë‚´ì„¼í„°_ë³´ìœ ì—¬ë¶€',
                    'ê³ ê°ë™ì„ í†µë¡œ': 'ê³ ê°ë™ì„ í†µë¡œ_ë³´ìœ ì—¬ë¶€',
                    'ë°©ì†¡ì„¼í„°': 'ë°©ì†¡ì„¼í„°_ë³´ìœ ì—¬ë¶€',
                    'ë¬¸í™”êµì‹¤': 'ë¬¸í™”êµì‹¤_ë³´ìœ ì—¬ë¶€',
                    'ê³µë™ë¬¼ë¥˜ì°½ê³ ': 'ê³µë™ë¬¼ë¥˜ì°½ê³ _ë³´ìœ ì—¬ë¶€',
                    'ì‹œì¥ì „ìš©ê³ ê°ì£¼ì°¨ì¥': 'ì‹œì¥ì „ìš© ê³ ê°ì£¼ì°¨ì¥_ë³´ìœ ì—¬ë¶€',
                    'êµìœ¡ì¥': 'êµìœ¡ì¥_ë³´ìœ ì—¬ë¶€',
                    'íšŒì˜ì‹¤': 'íšŒì˜ì‹¤_ë³´ìœ ì—¬ë¶€',
                    'ìë™ì‹¬ì¥ì¶©ê²©ê¸°': 'ìë™ì‹¬ì¥ì¶©ê²©ê¸°_ë³´ìœ ì—¬ë¶€'
                }
                
                original_col = facility_mapping.get(col, col)
                value = get_value_from_file(file1_market['row'], header1, original_col)
        
        final_row.append(value)
    
    return final_row

def extract_sido_from_address(addr):
    """ì£¼ì†Œì—ì„œ ì‹œë„ ì¶”ì¶œ"""
    if not addr:
        return ""
    
    addr = standardize_region(addr)
    
    sido_patterns = [
        'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 
        'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›ë„',
        'ì¶©ì²­ë¶ë„', 'ì¶©ì²­ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì „ë¼ë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
    ]
    
    for sido in sido_patterns:
        if sido in addr:
            return sido
    
    return ""

def extract_sigungu_from_address(addr):
    """ì£¼ì†Œì—ì„œ ì‹œêµ°êµ¬ ì¶”ì¶œ"""
    if not addr:
        return ""
    
    # ì‹œêµ°êµ¬ íŒ¨í„´ ì°¾ê¸°
    sigungu_pattern = r'([\w]+ì‹œ|[\w]+êµ°|[\w]+êµ¬)'
    matches = re.findall(sigungu_pattern, addr)
    
    if matches:
        # ì‹œë„ëª…ì´ ì•„ë‹Œ ì²« ë²ˆì§¸ ë§¤ì¹˜ë¥¼ ì‹œêµ°êµ¬ë¡œ ì‚¬ìš©
        sido_names = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 
                     'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ']
        
        for match in matches:
            if match not in sido_names:
                return match
    
    return ""

if __name__ == "__main__":
    smart_merge_csv_files() 